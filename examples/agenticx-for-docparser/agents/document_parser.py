#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æ–‡æ¡£è§£ææ™ºèƒ½ä½“

åŸºäºAgenticXæ¡†æ¶çš„æ–‡æ¡£è§£ææ™ºèƒ½ä½“ï¼Œé›†æˆMinerUå·¥å…·è¿›è¡ŒPDFæ–‡æ¡£è§£æã€‚
æ”¯æŒå¤šç§è§£ææ¨¡å¼å’Œå‚æ•°é…ç½®ï¼Œæä¾›æ™ºèƒ½åŒ–çš„æ–‡æ¡£å¤„ç†èƒ½åŠ›ã€‚
"""

import os
import logging
from pathlib import Path
from typing import Dict, Any, List, Optional
import zipfile
import tempfile
import shutil

import aiohttp

# å¯¼å…¥AgenticXæ ¸å¿ƒæ¨¡å—
from agenticx.core.agent import Agent, AgentContext, AgentResult
from agenticx.core.task import Task
from agenticx.llms.base import BaseLLMProvider
from agenticx.tools.base import BaseTool

logger = logging.getLogger(__name__)


class ParseDocumentTool(BaseTool):
    """æ–‡æ¡£è§£æå·¥å…·"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(
            name="parse_document",
            description="è§£æPDFã€Wordã€PPTç­‰æ–‡æ¡£ï¼Œæå–æ–‡æœ¬ã€è¡¨æ ¼ã€å…¬å¼ç­‰å†…å®¹"
        )
        self.config = config
        self.api_config = config.get("api", {})
        self.api_base = self.api_config.get("base", "https://mineru.net/api/v4")
        self.api_token = self.api_config.get("token", "")
    
    def _run(self, **kwargs) -> Dict[str, Any]:
        """åŒæ­¥æ‰§è¡Œæ–‡æ¡£è§£æ"""
        import asyncio
        return asyncio.run(self._arun(**kwargs))
    
    async def _arun(self, **kwargs) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œæ–‡æ¡£è§£æ"""
        try:
            file_path = kwargs.get("file_path")
            language = kwargs.get("language", "ch")
            enable_ocr = kwargs.get("enable_ocr", True)
            page_ranges = kwargs.get("page_ranges")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                return {
                    "success": False,
                    "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                }
            
            # ç›´æ¥è°ƒç”¨ MinerU API
            result = await self._call_mineru_api(
                file_path=file_path,
                language=language,
                enable_ocr=enable_ocr,
                page_ranges=page_ranges
            )
            return result
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£è§£æå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _call_mineru_api(self, file_path: str, language: str, enable_ocr: bool, page_ranges: Optional[str]) -> Dict[str, Any]:
        """è°ƒç”¨ MinerU API ä¸Šä¼ å¹¶è§£ææ–‡ä»¶"""
        import aiohttp
        import time
        from pathlib import Path
        
        try:
            # æ£€æŸ¥ API é…ç½®
            if not self.api_token:
                return {
                    "success": False,
                    "error": "MinerU API Token æœªé…ç½®"
                }
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            file_path_obj = Path(file_path)
            if not file_path_obj.exists():
                return {
                    "success": False,
                    "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                }
            
            logger.info(f"å¼€å§‹ä¸Šä¼ æ–‡ä»¶: {file_path}")
            
            async with aiohttp.ClientSession() as session:
                # 1. è·å–æ–‡ä»¶ä¸Šä¼ URL
                upload_result = await self._get_upload_url(session, file_path_obj, language, enable_ocr, page_ranges)
                if not upload_result["success"]:
                    return upload_result
                
                batch_id = upload_result["batch_id"]
                upload_url = upload_result["upload_url"]
                
                # 2. ä¸Šä¼ æ–‡ä»¶
                upload_file_result = await self._upload_file(session, file_path_obj, upload_url)
                if not upload_file_result["success"]:
                    return upload_file_result
                
                logger.info(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œbatch_id: {batch_id}")
                
                # 3. è½®è¯¢ä»»åŠ¡çŠ¶æ€
                return await self._poll_batch_task_status(session, batch_id)
                        
        except Exception as e:
            logger.error(f"MinerU API è°ƒç”¨å¼‚å¸¸: {e}")
            return {
                "success": False,
                "error": f"API è°ƒç”¨å¼‚å¸¸: {str(e)}"
            }
    
    async def _get_upload_url(self, session, file_path_obj: Path, language: str, enable_ocr: bool, page_ranges: Optional[str]) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶ä¸Šä¼ URL"""
        import time
        
        # å‡†å¤‡ä¸Šä¼ è¯·æ±‚
        upload_request = {
            "files": [
                {
                    "name": file_path_obj.name,
                    "is_ocr": enable_ocr,
                    "data_id": f"upload_{int(time.time())}"
                }
            ],
            "enable_formula": True,  # å¯ç”¨å…¬å¼è¯†åˆ«
            "enable_table": True     # å¯ç”¨è¡¨æ ¼è¯†åˆ«
        }
        
        # æ·»åŠ è¯­è¨€å‚æ•°ï¼ˆå¦‚æœä¸æ˜¯autoï¼‰
        if language and language != "auto":
            upload_request["language"] = language
            
        # æ·»åŠ é¡µç èŒƒå›´ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if page_ranges:
            upload_request["page_ranges"] = page_ranges
        
        logger.info(f"è¯·æ±‚æ–‡ä»¶ä¸Šä¼ URLï¼Œæ•°æ®: {upload_request}")
        
        try:
            async with session.post(
                f"{self.api_base}/file-urls/batch",
                json=upload_request,
                headers={
                    "Authorization": f"Bearer {self.api_token}",
                    "Content-Type": "application/json",
                    "Accept": "*/*"
                },
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                if response.status == 200:
                    upload_data = await response.json()
                    logger.info(f"ä¸Šä¼ URLå“åº”: {upload_data}")
                    
                    if upload_data.get("code") != 0 or "data" not in upload_data:
                        return {
                            "success": False,
                            "error": f"è·å–ä¸Šä¼ URLå¤±è´¥: {upload_data}"
                        }
                    
                    batch_data = upload_data["data"]
                    batch_id = batch_data.get("batch_id")
                    file_urls = batch_data.get("file_urls", [])
                    
                    if not batch_id or not file_urls:
                        return {
                            "success": False,
                            "error": f"å“åº”ä¸­ç¼ºå°‘batch_idæˆ–file_urls: {batch_data}"
                        }
                    
                    return {
                        "success": True,
                        "batch_id": batch_id,
                        "upload_url": file_urls[0]  # file_urls æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
                    }
                else:
                    error_text = await response.text()
                    return {
                        "success": False,
                        "error": f"è·å–ä¸Šä¼ URLå¤±è´¥ (çŠ¶æ€ç : {response.status}): {error_text}"
                    }
        except Exception as e:
            return {
                "success": False,
                "error": f"è·å–ä¸Šä¼ URLå¼‚å¸¸: {str(e)}"
            }
    
    async def _upload_file(self, session, file_path_obj: Path, upload_url: str) -> Dict[str, Any]:
        """ä¸Šä¼ æ–‡ä»¶åˆ°æŒ‡å®šURL"""
        import httpx
        
        try:
            logger.info(f"ä¸Šä¼ æ–‡ä»¶åˆ°: {upload_url}")
            
            with open(file_path_obj, 'rb') as f:
                file_content = f.read()
            
            # ä½¿ç”¨httpxå®¢æˆ·ç«¯ï¼ŒåŒ¹é…åŸå§‹MinerUå·¥å…·çš„å®ç°
            async with httpx.AsyncClient() as client:
                response = await client.put(
                    upload_url,
                    content=file_content,
                    headers={
                        # ä¸è®¾ç½®Content-Typeï¼Œè®©ç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹
                    },
                    timeout=60.0  # ä¸Šä¼ å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
                )
                
                if response.status_code in [200, 201]:
                    logger.info("æ–‡ä»¶ä¸Šä¼ æˆåŠŸ")
                    return {"success": True}
                else:
                    error_text = response.text
                    return {
                        "success": False,
                        "error": f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥ (çŠ¶æ€ç : {response.status_code}): {error_text}"
                    }
        except Exception as e:
            return {
                "success": False,
                "error": f"æ–‡ä»¶ä¸Šä¼ å¼‚å¸¸: {str(e)}"
            }
    
    async def _poll_task_status(self, session, task_id: str, headers: Dict[str, str]) -> Dict[str, Any]:
        """è½®è¯¢å•ä¸ªä»»åŠ¡çŠ¶æ€"""
        import asyncio
        
        max_attempts = 60  # æœ€å¤šè½®è¯¢60æ¬¡
        interval = 5  # æ¯5ç§’è½®è¯¢ä¸€æ¬¡
        
        for attempt in range(max_attempts):
            try:
                async with session.get(
                    f"{self.api_base}/extract/task/{task_id}",
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        
                        if result.get("code") == 0 and "data" in result:
                            task_data = result["data"]
                            state = task_data.get("state", "").lower()
                            
                            if state == "done":
                                return {
                                    "success": True,
                                    "content": task_data.get("markdown_url", ""),
                                    "full_zip_url": task_data.get("full_zip_url", ""),
                                    "task_id": task_id
                                }
                            elif state == "failed":
                                return {
                                    "success": False,
                                    "error": task_data.get("error", "ä»»åŠ¡å¤±è´¥")
                                }
                            elif state in ["pending", "running", "converting"]:
                                logger.info(f"ä»»åŠ¡ {task_id} çŠ¶æ€: {state}ï¼Œç»§ç»­ç­‰å¾…...")
                                await asyncio.sleep(interval)
                                continue
                        else:
                            return {
                                "success": False,
                                "error": f"APIå“åº”æ ¼å¼é”™è¯¯: {result}"
                            }
                    else:
                        return {
                            "success": False,
                            "error": f"æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥ (çŠ¶æ€ç : {response.status})"
                        }
            except Exception as e:
                return {
                    "success": False,
                    "error": f"æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¼‚å¸¸: {str(e)}"
                }
        
        return {
            "success": False,
            "error": "ä»»åŠ¡è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
        }
    
    async def _poll_batch_task_status(self, session, batch_id: str) -> Dict[str, Any]:
        """è½®è¯¢æ‰¹é‡ä»»åŠ¡çŠ¶æ€"""
        import asyncio
        
        max_attempts = 100  # æœ€å¤šè½®è¯¢100æ¬¡
        interval = 3  # æ¯3ç§’è½®è¯¢ä¸€æ¬¡
        
        logger.info(f"å¼€å§‹è½®è¯¢æ‰¹é‡ä»»åŠ¡çŠ¶æ€ï¼Œbatch_id: {batch_id}")
        
        for attempt in range(max_attempts):
            try:
                async with session.get(
                    f"{self.api_base}/extract-results/batch/{batch_id}",
                    headers={
                        "Authorization": f"Bearer {self.api_token}",
                        "Content-Type": "application/json",
                        "Accept": "*/*"
                    },
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        logger.debug(f"æ‰¹é‡ä»»åŠ¡è½®è¯¢å“åº”æ•°æ®: {data}")
                        
                        # å¤„ç†æ‰¹é‡ä»»åŠ¡APIçš„å“åº”æ ¼å¼
                        if data.get("code") == 0 and "data" in data:
                            extract_results = data["data"].get("extract_result", [])
                            if not extract_results:
                                logger.info(f"æ‰¹é‡ä»»åŠ¡ {batch_id} æš‚æ— ç»“æœï¼Œç»§ç»­ç­‰å¾…...")
                                await asyncio.sleep(interval)
                                continue
                            
                            # è·å–ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„è§£æç»“æœ
                            result = extract_results[0]
                            state = result.get("state", "").lower()
                            logger.debug(f"æ‰¹é‡ä»»åŠ¡çŠ¶æ€: {state}, å®Œæ•´æ•°æ®: {result}")
                            
                            if state == "done":
                                # æ‰¹é‡ä»»åŠ¡å®Œæˆï¼Œè¿”å›å®Œæ•´çš„ä»»åŠ¡æ•°æ®
                                full_zip_url = result.get("full_zip_url")
                                markdown_url = result.get("markdown_url")
                                logger.info(f"æ‰¹é‡ä»»åŠ¡å®Œæˆï¼ŒZIP URL: {full_zip_url}")
                                return {
                                    "success": True,
                                    "content": markdown_url or "",
                                    "full_zip_url": full_zip_url or "",
                                    "task_id": batch_id,
                                    "data": result
                                }
                            elif state == "failed":
                                # æ‰¹é‡ä»»åŠ¡å¤±è´¥
                                error_msg = result.get("err_msg", "æ‰¹é‡ä»»åŠ¡å¤±è´¥")
                                return {
                                    "success": False,
                                    "error": error_msg,
                                    "task_id": batch_id
                                }
                            elif state in ["pending", "running", "converting"]:
                                # æ‰¹é‡ä»»åŠ¡è¿›è¡Œä¸­
                                progress = result.get("extract_progress", {})
                                extracted_pages = progress.get("extracted_pages", 0)
                                total_pages = progress.get("total_pages", 0)
                                logger.info(f"æ‰¹é‡ä»»åŠ¡ {batch_id} çŠ¶æ€: {state}, è¿›åº¦: {extracted_pages}/{total_pages}")
                                await asyncio.sleep(interval)
                                continue
                            else:
                                # æœªçŸ¥çŠ¶æ€ï¼Œç»§ç»­ç­‰å¾…
                                logger.warning(f"æ‰¹é‡ä»»åŠ¡ {batch_id} æœªçŸ¥çŠ¶æ€: {state}")
                                await asyncio.sleep(interval)
                                continue
                        else:
                            # APIè°ƒç”¨å¤±è´¥
                            error_msg = data.get("msg", "æ‰¹é‡ä»»åŠ¡APIè°ƒç”¨å¤±è´¥")
                            return {
                                "success": False,
                                "error": f"æ‰¹é‡ä»»åŠ¡APIå“åº”é”™è¯¯: {error_msg}"
                            }
                    else:
                        error_text = await response.text()
                        return {
                            "success": False,
                            "error": f"æŸ¥è¯¢æ‰¹é‡ä»»åŠ¡çŠ¶æ€å¤±è´¥ (çŠ¶æ€ç : {response.status}): {error_text}"
                        }
                        
            except Exception as e:
                logger.error(f"è½®è¯¢æ‰¹é‡ä»»åŠ¡çŠ¶æ€å¤±è´¥ (å°è¯• {attempt + 1}): {e}")
                if attempt == max_attempts - 1:
                    return {
                        "success": False,
                        "error": f"è½®è¯¢æ‰¹é‡ä»»åŠ¡çŠ¶æ€å¼‚å¸¸: {str(e)}"
                    }
                await asyncio.sleep(interval)
        
        return {
            "success": False,
            "error": f"æ‰¹é‡ä»»åŠ¡ {batch_id} è½®è¯¢è¶…æ—¶"
        }


class GetSupportedLanguagesTool(BaseTool):
    """è·å–æ”¯æŒçš„OCRè¯­è¨€åˆ—è¡¨å·¥å…·"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(
            name="get_supported_languages",
            description="è·å–MinerUæ”¯æŒçš„OCRè¯­è¨€åˆ—è¡¨"
        )
        self.config = config
        self.api_config = config.get("api", {})
        self.api_base = self.api_config.get("base", "https://mineru.net/api/v4")
        self.api_token = self.api_config.get("token", "")
    
    def _run(self, **kwargs) -> List[str]:
        """åŒæ­¥è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨"""
        import asyncio
        return asyncio.run(self._arun(**kwargs))
    
    async def _arun(self, **kwargs) -> List[str]:
        """å¼‚æ­¥è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨"""
        try:
            result = await self._call_languages_api()
            return result
        except Exception as e:
            logger.error(f"è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨å¤±è´¥: {e}")
            return ["ch", "en", "auto"]
    
    async def _call_languages_api(self) -> List[str]:
        """è°ƒç”¨ MinerU API è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨"""
        import aiohttp
        
        try:
            # å¦‚æœæ²¡æœ‰é…ç½® APIï¼Œè¿”å›é»˜è®¤è¯­è¨€åˆ—è¡¨
            if not self.api_token:
                return ["ch", "en", "auto"]
            
            async with aiohttp.ClientSession() as session:
                headers = {
                    'Authorization': f'Bearer {self.api_token}'
                }
                
                async with session.get(
                    f"{self.api_base}/api/languages",
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        if isinstance(result, list):
                            return result
                        elif isinstance(result, dict) and "languages" in result:
                            return result["languages"]
                        else:
                            return ["ch", "en", "auto"]
                    else:
                        logger.warning(f"è·å–è¯­è¨€åˆ—è¡¨ API è°ƒç”¨å¤±è´¥ (çŠ¶æ€ç : {response.status})")
                        return ["ch", "en", "auto"]
                        
        except Exception as e:
            logger.warning(f"è·å–è¯­è¨€åˆ—è¡¨ API è°ƒç”¨å¼‚å¸¸: {e}")
            return ["ch", "en", "auto"]


class AnalyzeDocumentStructureTool(BaseTool):
    """æ–‡æ¡£ç»“æ„åˆ†æå·¥å…·"""
    
    def __init__(self):
        super().__init__(
            name="analyze_document_structure",
            description="åˆ†ææ–‡æ¡£çš„åŸºæœ¬ç»“æ„ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–‡ä»¶å¤§å°ã€ç±»å‹ã€é¡µæ•°ç­‰"
        )
    
    def _run(self, **kwargs) -> Dict[str, Any]:
        """åˆ†ææ–‡æ¡£ç»“æ„"""
        try:
            file_path = kwargs.get("file_path")
            
            if not os.path.exists(file_path):
                return {
                    "success": False,
                    "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                }
            
            file_path_obj = Path(file_path)
            file_size = file_path_obj.stat().st_size
            file_type = file_path_obj.suffix.lower()
            
            # ä¼°ç®—é¡µæ•°ï¼ˆç®€å•ä¼°ç®—ï¼‰
            estimated_pages = max(1, file_size // (1024 * 100))  # å‡è®¾æ¯é¡µçº¦100KB
            
            return {
                "success": True,
                "file_name": file_path_obj.name,
                "file_size": file_size,
                "file_type": file_type,
                "estimated_pages": estimated_pages,
                "supported_features": self._get_supported_features(file_type)
            }
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£ç»“æ„åˆ†æå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _get_supported_features(self, file_type: str) -> List[str]:
        """è·å–æ–‡ä»¶ç±»å‹æ”¯æŒçš„åŠŸèƒ½"""
        features = ["æ–‡æœ¬æå–"]
        
        if file_type in [".pdf", ".docx", ".pptx"]:
            features.extend(["è¡¨æ ¼è¯†åˆ«", "å…¬å¼è¯†åˆ«", "å›¾ç‰‡æå–"])
        
        return features


class ExtractDocumentMetadataTool(BaseTool):
    """æ–‡æ¡£å…ƒæ•°æ®æå–å·¥å…·"""
    
    def __init__(self):
        super().__init__(
            name="extract_document_metadata",
            description="æå–æ–‡æ¡£çš„å…ƒæ•°æ®ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–‡ä»¶åã€å¤§å°ã€åˆ›å»ºæ—¶é—´ç­‰"
        )
    
    def _run(self, **kwargs) -> Dict[str, Any]:
        """æå–æ–‡æ¡£å…ƒæ•°æ®"""
        try:
            file_path = kwargs.get("file_path")
            
            if not os.path.exists(file_path):
                return {
                    "success": False,
                    "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                }
            
            file_path_obj = Path(file_path)
            stat = file_path_obj.stat()
            
            return {
                "success": True,
                "file_name": file_path_obj.name,
                "file_size": stat.st_size,
                "file_type": file_path_obj.suffix.lower(),
                "created_time": stat.st_ctime,
                "modified_time": stat.st_mtime,
                "absolute_path": str(file_path_obj.absolute())
            }
            
        except Exception as e:
            logger.error(f"å…ƒæ•°æ®æå–å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }


class DocumentParserAgent(Agent):
    """
    æ–‡æ¡£è§£ææ™ºèƒ½ä½“
    
    åŸºäºAgenticXæ¡†æ¶çš„æ™ºèƒ½ä½“ï¼Œä¸“é—¨ç”¨äºæ–‡æ¡£è§£æä»»åŠ¡ã€‚
    é›†æˆMinerUå·¥å…·ï¼Œæ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼çš„è§£æå’Œå¤„ç†ã€‚
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–æ–‡æ¡£è§£ææ™ºèƒ½ä½“
        
        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«LLMå’ŒMinerUé…ç½®
        """
        # ä»é…ç½®ä¸­æå–æ™ºèƒ½ä½“ä¿¡æ¯
        agent_config = config.get("agent", {})
        
        # å°†é…ç½®å­˜å‚¨åœ¨memory_configä¸­ï¼Œé¿å…Pydanticå­—æ®µå†²çª
        memory_config = {
            "config": config,
            "mineru_config": config.get("mineru", {}),
            "tools": {},
            "conversation_state": {
                'stage': 'initial',  # initial, waiting_for_file, parsing, completed
                'current_file_path': None,
                'parse_request': None,
                'has_introduced': False
            }
        }
        
        super().__init__(
            name=agent_config.get("name", "DocumentParser"),
            role=agent_config.get("role", "æ–‡æ¡£è§£æä¸“å®¶"),
            goal=agent_config.get("goal", "é«˜æ•ˆå‡†ç¡®åœ°è§£æå„ç§æ ¼å¼çš„æ–‡æ¡£"),
            backstory=agent_config.get("backstory", "æˆ‘æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£è§£æåŠ©æ‰‹"),
            organization_id="default",
            memory_config=memory_config
        )
        
        # åˆå§‹åŒ–å·¥å…·
        self._initialize_tools()
        
        logger.info(f"æ–‡æ¡£è§£ææ™ºèƒ½ä½“ {self.name} åˆå§‹åŒ–å®Œæˆ")
    
    @property
    def conversation_state(self) -> Dict[str, Any]:
        """è·å–å¯¹è¯çŠ¶æ€"""
        return self.memory_config.get("conversation_state", {})
    
    def update_conversation_state(self, **kwargs):
        """æ›´æ–°å¯¹è¯çŠ¶æ€"""
        if "conversation_state" not in self.memory_config:
            self.memory_config["conversation_state"] = {}
        self.memory_config["conversation_state"].update(kwargs)
    
    def _initialize_tools(self):
        """åˆå§‹åŒ–å·¥å…·"""
        try:
            mineru_config = self.memory_config["mineru_config"]
            
            # åˆå§‹åŒ–MinerUå·¥å…·
            self.memory_config["tools"]["parse_document_tool"] = ParseDocumentTool(mineru_config)
            self.memory_config["tools"]["get_languages_tool"] = GetSupportedLanguagesTool(mineru_config)
            self.memory_config["tools"]["analyze_structure_tool"] = AnalyzeDocumentStructureTool()
            self.memory_config["tools"]["extract_metadata_tool"] = ExtractDocumentMetadataTool()
            
            logger.info("å·¥å…·åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"å·¥å…·åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def parse_document(
        self,
        file_path: str,
        mode: Optional[str] = None,
        language: Optional[str] = None,
        enable_formula: Optional[bool] = None,
        enable_table: Optional[bool] = None,
        page_ranges: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        è§£ææ–‡æ¡£
        
        Args:
            file_path: æ–‡æ¡£æ–‡ä»¶è·¯å¾„
            mode: è§£ææ¨¡å¼ (å·²å¼ƒç”¨ï¼Œç°åœ¨æ€»æ˜¯ä½¿ç”¨è¿œç¨‹API)
            language: OCRè¯­è¨€
            enable_formula: æ˜¯å¦å¯ç”¨å…¬å¼è¯†åˆ« (å·²å¼ƒç”¨)
            enable_table: æ˜¯å¦å¯ç”¨è¡¨æ ¼è¯†åˆ« (å·²å¼ƒç”¨)
            page_ranges: é¡µç èŒƒå›´
            
        Returns:
            è§£æç»“æœ
        """
        tool = self.memory_config["tools"]["parse_document_tool"]
        
        return await tool._arun(
            file_path=file_path,
            language=language or "ch",
            enable_ocr=True,
            page_ranges=page_ranges
        )
    
    async def get_supported_languages(self, mode: Optional[str] = None) -> List[str]:
        """
        è·å–æ”¯æŒçš„OCRè¯­è¨€åˆ—è¡¨
        
        Args:
            mode: æŸ¥è¯¢æ¨¡å¼ (å·²å¼ƒç”¨)
            
        Returns:
            è¯­è¨€åˆ—è¡¨
        """
        tool = self.memory_config["tools"]["get_languages_tool"]
        
        return await tool._arun()
    
    def analyze_document_structure(self, file_path: str) -> Dict[str, Any]:
        """
        åˆ†ææ–‡æ¡£ç»“æ„
        
        Args:
            file_path: æ–‡æ¡£æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ–‡æ¡£ç»“æ„ä¿¡æ¯
        """
        tool = self.memory_config["tools"]["analyze_structure_tool"]
        return tool._run(file_path=file_path)
    
    def extract_document_metadata(self, file_path: str) -> Dict[str, Any]:
        """
        æå–æ–‡æ¡£å…ƒæ•°æ®
        
        Args:
            file_path: æ–‡æ¡£æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ–‡æ¡£å…ƒæ•°æ®
        """
        tool = self.memory_config["tools"]["extract_metadata_tool"]
        return tool._run(file_path=file_path)
    
    def execute(self, task: Task, context: AgentContext) -> AgentResult:
        """
        æ‰§è¡Œä»»åŠ¡ï¼ˆAgenticX Agentæ¥å£æ–¹æ³•ï¼‰
        
        Args:
            task: æ‰§è¡Œä»»åŠ¡
            context: Agentä¸Šä¸‹æ–‡
            
        Returns:
            AgentResult: æ‰§è¡Œç»“æœ
        """
        try:
            task_type = task.context.get("task_type", "parse_document")
            
            if task_type == "parse_document":
                result = self._handle_parse_document_task(task)
            elif task_type == "get_languages":
                result = self._handle_get_languages_task(task)
            elif task_type == "analyze_structure":
                result = self._handle_analyze_structure_task(task)
            elif task_type == "extract_metadata":
                result = self._handle_extract_metadata_task(task)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task_type}")
            
            return AgentResult(
                agent_id=self.id,
                task_id=task.id,
                success=True,
                output=result,
                metadata={"task_type": task_type}
            )
            
        except Exception as e:
            logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            return AgentResult(
                agent_id=self.id,
                task_id=task.id,
                success=False,
                error=str(e),
                metadata={"task_type": task.context.get("task_type", "unknown")}
            )
    
    def _handle_parse_document_task(self, task: Task) -> Dict[str, Any]:
        """å¤„ç†æ–‡æ¡£è§£æä»»åŠ¡"""
        import asyncio
        
        file_path = task.context.get("file_path")
        if not file_path:
            raise ValueError("ç¼ºå°‘æ–‡ä»¶è·¯å¾„å‚æ•°")
        
        return asyncio.run(self.parse_document(
            file_path=file_path,
            mode=task.context.get("mode"),
            language=task.context.get("language"),
            enable_formula=task.context.get("enable_formula"),
            enable_table=task.context.get("enable_table"),
            page_ranges=task.context.get("page_ranges")
        ))
    
    def _handle_get_languages_task(self, task: Task) -> List[str]:
        """å¤„ç†è·å–è¯­è¨€åˆ—è¡¨ä»»åŠ¡"""
        import asyncio
        
        return asyncio.run(self.get_supported_languages(
            mode=task.context.get("mode")
        ))
    
    def _handle_analyze_structure_task(self, task: Task) -> Dict[str, Any]:
        """å¤„ç†æ–‡æ¡£ç»“æ„åˆ†æä»»åŠ¡"""
        file_path = task.context.get("file_path")
        if not file_path:
            raise ValueError("ç¼ºå°‘æ–‡ä»¶è·¯å¾„å‚æ•°")
        
        return self.analyze_document_structure(file_path)
    
    def _handle_extract_metadata_task(self, task: Task) -> Dict[str, Any]:
        """å¤„ç†å…ƒæ•°æ®æå–ä»»åŠ¡"""
        file_path = task.context.get("file_path")
        if not file_path:
            raise ValueError("ç¼ºå°‘æ–‡ä»¶è·¯å¾„å‚æ•°")
        
        return self.extract_document_metadata(file_path)
    
    async def process_document_request(self, user_input: str) -> str:
        """
        å¤„ç†ç”¨æˆ·çš„æ–‡æ¡£è§£æè¯·æ±‚ï¼Œæ”¯æŒçŠ¶æ€ç®¡ç†å’ŒçœŸæ­£çš„æ–‡æ¡£è§£æ
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
            
        Returns:
            str: æ™ºèƒ½ä½“çš„å›å¤
        """
        try:
            user_input_lower = user_input.lower().strip()
            
            # æ£€æµ‹æ–‡ä»¶è·¯å¾„
            detected_file_path = self._detect_file_path(user_input)
            
            # æ£€æµ‹è§£ææ„å›¾
            parse_keywords = ['è§£æ', 'parse', 'å¤„ç†', 'process', 'åˆ†æ', 'analyze', 'æå–', 'extract']
            has_parse_intent = any(keyword in user_input_lower for keyword in parse_keywords)
            
            # çŠ¶æ€æœºå¤„ç†
            if self.conversation_state['stage'] == 'initial':
                if detected_file_path:
                    # ç”¨æˆ·ç›´æ¥æä¾›äº†æ–‡ä»¶è·¯å¾„
                    return await self._handle_file_path_provided(detected_file_path)
                elif has_parse_intent or any(word in user_input_lower for word in ['æ–‡æ¡£', 'pdf', 'word', 'ppt']):
                    # ç”¨æˆ·è¡¨è¾¾äº†è§£ææ„å›¾ä½†æ²¡æœ‰æä¾›è·¯å¾„
                    self.update_conversation_state(stage='waiting_for_file', has_introduced=True)
                    return """å¥½çš„ï¼æˆ‘æ¥å¸®æ‚¨è§£ææ–‡æ¡£ã€‚

è¯·æä¾›æ‚¨è¦è§£æçš„æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ï¼š
â€¢ `/Users/ç”¨æˆ·å/Desktop/æ–‡æ¡£.pdf`
â€¢ `C:\\Users\\ç”¨æˆ·å\\Documents\\æ–‡æ¡£.docx`

æˆ‘æ”¯æŒè§£æ PDFã€Wordã€PowerPoint ç­‰æ ¼å¼çš„æ–‡æ¡£ï¼Œå¯ä»¥æå–æ–‡æœ¬ã€è¡¨æ ¼ã€å…¬å¼ç­‰å†…å®¹ã€‚"""
                else:
                    # é¦–æ¬¡é—®å€™æˆ–å…¶ä»–è¯¢é—®
                    if not self.conversation_state.get('has_introduced', False):
                        self.update_conversation_state(has_introduced=True)
                        return self._get_introduction_response(user_input)
                    else:
                        return self._get_contextual_response(user_input)
            
            elif self.conversation_state['stage'] == 'waiting_for_file':
                if detected_file_path:
                    # ç”¨æˆ·æä¾›äº†æ–‡ä»¶è·¯å¾„
                    return await self._handle_file_path_provided(detected_file_path)
                else:
                    return """è¯·æä¾›æ‚¨è¦è§£æçš„æ–‡ä»¶è·¯å¾„ã€‚

ä¾‹å¦‚ï¼š
â€¢ `/Users/damon/Desktop/dinov3_paper.pdf`
â€¢ `C:\\Documents\\æŠ¥å‘Š.docx`

æˆ–è€…æ‚¨å¯ä»¥è¾“å…¥ 'quit' é€€å‡ºå¯¹è¯ã€‚"""
            
            elif self.conversation_state['stage'] == 'parsing':
                return "æ–‡æ¡£æ­£åœ¨è§£æä¸­ï¼Œè¯·è€å¿ƒç­‰å¾…..."
            
            elif self.conversation_state['stage'] == 'completed':
                if detected_file_path:
                    # ç”¨æˆ·æƒ³è§£ææ–°æ–‡ä»¶
                    return await self._handle_file_path_provided(detected_file_path)
                else:
                    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰è§£ææ„å›¾
                    if has_parse_intent or any(word in user_input_lower for word in ['æ–‡æ¡£', 'pdf', 'word', 'ppt', 'è§£æ', 'å¤„ç†']):
                        # ç”¨æˆ·æƒ³è¦è§£ææ–°æ–‡æ¡£ä½†æ²¡æœ‰æä¾›è·¯å¾„
                        return """å¥½çš„ï¼æˆ‘æ¥å¸®æ‚¨è§£ææ–°çš„æ–‡æ¡£ã€‚

è¯·æä¾›æ‚¨è¦è§£æçš„æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ï¼š
â€¢ `/Users/ç”¨æˆ·å/Desktop/æ–‡æ¡£.pdf`
â€¢ `C:\\Users\\ç”¨æˆ·å\\Documents\\æ–‡æ¡£.docx`

æˆ–è€…æ‚¨å¯ä»¥è¾“å…¥ 'quit' é€€å‡ºå¯¹è¯ã€‚"""
                    else:
                        # ç”¨æˆ·è¯¢é—®å…¶ä»–é—®é¢˜ï¼Œä½¿ç”¨æ™ºèƒ½å›å¤
                        return self._get_contextual_response(user_input)
            
            return self._get_contextual_response(user_input)
            
        except Exception as e:
            logger.error(f"å¤„ç†ç”¨æˆ·è¯·æ±‚å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
    
    def _detect_file_path(self, user_input: str) -> Optional[str]:
        """æ£€æµ‹ç”¨æˆ·è¾“å…¥ä¸­çš„æ–‡ä»¶è·¯å¾„"""
        import re
        
        # æ£€æµ‹æ–‡ä»¶è·¯å¾„æ¨¡å¼ï¼ˆæ”¯æŒåŒ…å«ç©ºæ ¼çš„è·¯å¾„ï¼‰
        file_path_patterns = [
            r"'([^']+\.[a-zA-Z0-9]+)'",  # å•å¼•å·åŒ…å›´çš„è·¯å¾„ '/path/to/file.ext'
            r'"([^"]+\.[a-zA-Z0-9]+)"',  # åŒå¼•å·åŒ…å›´çš„è·¯å¾„ "/path/to/file.ext"
            r'\.?/[^/\n]+(?:/[^/\n]+)*\.[a-zA-Z0-9]+',  # Unixè·¯å¾„ /path/to/file.ext æˆ– ./path/to/file.ext
            r'[A-Za-z]:\\[^\\:\n]+(?:\\[^\\:\n]+)*\.[a-zA-Z0-9]+',  # Windowsè·¯å¾„ C:\path\to\file.ext
            r'[^\s/\\\n]+\.[a-zA-Z0-9]+',  # ç®€å•æ–‡ä»¶å file.ext
        ]
        
        for i, pattern in enumerate(file_path_patterns):
            match = re.search(pattern, user_input)
            if match:
                # å‰ä¸¤ä¸ªæ¨¡å¼ï¼ˆå¼•å·åŒ…å›´ï¼‰æœ‰åˆ†ç»„ï¼Œä½¿ç”¨group(1)ï¼Œå…¶ä»–ä½¿ç”¨group(0)
                if i < 2:  # å¼•å·åŒ…å›´çš„æ¨¡å¼
                    return match.group(1)
                else:
                    return match.group(0)
        return None
    
    async def _handle_file_path_provided(self, file_path: str) -> str:
        """å¤„ç†ç”¨æˆ·æä¾›çš„æ–‡ä»¶è·¯å¾„"""
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        file_path = os.path.abspath(file_path)
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            return f"""âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼š`{file_path}`

è¯·æ£€æŸ¥ï¼š
â€¢ æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
â€¢ æ–‡ä»¶æ˜¯å¦å­˜åœ¨
â€¢ æ˜¯å¦æœ‰è®¿é—®æƒé™

è¯·æä¾›æ­£ç¡®çš„æ–‡ä»¶è·¯å¾„ï¼Œæˆ–è¾“å…¥ 'quit' é€€å‡ºå¯¹è¯ã€‚"""
        
        # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
        supported_extensions = ['.pdf', '.docx', '.pptx', '.doc', '.ppt']
        file_ext = os.path.splitext(file_path)[1].lower()
        if file_ext not in supported_extensions:
            return f"""âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š`{file_ext}`

æ”¯æŒçš„æ ¼å¼ï¼š
â€¢ PDF (.pdf)
â€¢ Word (.docx, .doc)  
â€¢ PowerPoint (.pptx, .ppt)

è¯·æä¾›æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œæˆ–è¾“å…¥ 'quit' é€€å‡ºå¯¹è¯ã€‚"""
        
        # å¼€å§‹è§£æ
        self.update_conversation_state(stage='parsing', current_file_path=file_path)
        
        try:
            # æ˜¾ç¤ºå¼€å§‹è§£æçš„æ¶ˆæ¯
            logger.info(f"å¼€å§‹è§£ææ–‡æ¡£: {file_path}")
            
            # è¿”å›å¼€å§‹è§£æçš„æ¶ˆæ¯ï¼Œç„¶ååœ¨åå°è¿›è¡Œè§£æ
            import asyncio
            
            # åˆ›å»ºä¸€ä¸ªå¼‚æ­¥ä»»åŠ¡æ¥å¤„ç†è§£æï¼ŒåŒæ—¶æä¾›è¿›åº¦åé¦ˆ
            async def parse_with_progress():
                # æ¨¡æ‹Ÿè¿›åº¦åé¦ˆ
                await asyncio.sleep(1)  # æ¨¡æ‹Ÿåˆå§‹åŒ–æ—¶é—´
                logger.info("æ­£åœ¨è¿æ¥ MinerU æœåŠ¡...")
                
                await asyncio.sleep(1)  # æ¨¡æ‹Ÿè¿æ¥æ—¶é—´
                logger.info("æ­£åœ¨ä¸Šä¼ æ–‡æ¡£...")
                
                await asyncio.sleep(2)  # æ¨¡æ‹Ÿä¸Šä¼ æ—¶é—´
                logger.info("æ­£åœ¨è§£ææ–‡æ¡£å†…å®¹...")
                
                # è°ƒç”¨å®é™…çš„è§£ææ–¹æ³•
                result = await self.parse_document(file_path)
                return result
            
            # æ‰§è¡Œè§£æ
            result = await parse_with_progress()
            
            if result.get('success', False):
                # ä¸‹è½½å¹¶è§£å‹è§£æç»“æœ
                output_path = await self._download_and_extract_results(file_path, result)
                
                self.update_conversation_state(stage='completed')
                
                return f"""âœ… æ–‡æ¡£è§£æå®Œæˆï¼

ğŸ“„ **åŸæ–‡ä»¶**: `{file_path}`
ğŸ“ **ç»“æœæ–‡ä»¶å¤¹**: `{output_path}`

ğŸ“Š **è§£æå†…å®¹**:
â€¢ å®Œæ•´çš„Markdownæ–‡æ¡£ (full.md)
â€¢ æå–çš„å›¾ç‰‡æ–‡ä»¶å¤¹ (images/)
â€¢ å¸ƒå±€ä¿¡æ¯æ–‡ä»¶ (layout.json)
â€¢ åŸå§‹PDFæ–‡ä»¶

æ‚¨å¯ä»¥ï¼š
â€¢ æä¾›æ–°çš„æ–‡ä»¶è·¯å¾„ç»§ç»­è§£æå…¶ä»–æ–‡æ¡£
â€¢ è¾“å…¥ 'quit' é€€å‡ºå¯¹è¯"""
            else:
                self.conversation_state['stage'] = 'initial'
                error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
                return f"""âŒ æ–‡æ¡£è§£æå¤±è´¥ï¼š{error_msg}

è¯·æ£€æŸ¥ï¼š
â€¢ æ–‡ä»¶æ˜¯å¦æŸå
â€¢ æ–‡ä»¶æ˜¯å¦åŠ å¯†
â€¢ ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸

æ‚¨å¯ä»¥é‡æ–°æä¾›æ–‡ä»¶è·¯å¾„ï¼Œæˆ–è¾“å…¥ 'quit' é€€å‡ºå¯¹è¯ã€‚"""
                
        except Exception as e:
            self.update_conversation_state(stage='initial')
            logger.error(f"è§£ææ–‡æ¡£æ—¶å‡ºé”™: {e}")
            return f"""âŒ è§£æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}

è¯·é‡æ–°æä¾›æ–‡ä»¶è·¯å¾„ï¼Œæˆ–è¾“å…¥ 'quit' é€€å‡ºå¯¹è¯ã€‚"""
    
    async def _download_and_extract_results(self, original_file_path: str, result: Dict[str, Any]) -> str:
        """ä¸‹è½½å¹¶è§£å‹MinerUè¿”å›çš„ZIPæ–‡ä»¶"""
        try:
            # è·å–ZIPä¸‹è½½é“¾æ¥
            full_zip_url = result.get('full_zip_url')
            if not full_zip_url:
                logger.error("æœªæ‰¾åˆ°ZIPä¸‹è½½é“¾æ¥")
                return await self._save_parse_result(original_file_path, result)
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = Path("./outputs")
            output_dir.mkdir(exist_ok=True)
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å¤¹å
            original_name = Path(original_file_path).stem
            task_id = result.get('task_id', '')
            if task_id:
                # ä½¿ç”¨ç±»ä¼¼ dinov3_paper-2f2e3594f64f çš„æ ¼å¼
                folder_name = f"{original_name}-{task_id[:12]}"
            else:
                # å¦‚æœæ²¡æœ‰task_idï¼Œä½¿ç”¨æ—¶é—´æˆ³
                timestamp = __import__('datetime').datetime.now().strftime("%Y%m%d_%H%M%S")
                folder_name = f"{original_name}_{timestamp}"
            
            output_folder = output_dir / folder_name
            
            # å¦‚æœæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œåˆ é™¤å®ƒ
            if output_folder.exists():
                shutil.rmtree(output_folder)
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶æ¥ä¸‹è½½ZIP
            with tempfile.NamedTemporaryFile(suffix='.zip', delete=False) as temp_file:
                temp_zip_path = temp_file.name
                
                # ä¸‹è½½ZIPæ–‡ä»¶
                logger.info(f"æ­£åœ¨ä¸‹è½½ZIPæ–‡ä»¶: {full_zip_url}")
                async with aiohttp.ClientSession() as session:
                    async with session.get(full_zip_url) as response:
                        if response.status == 200:
                            content = await response.read()
                            temp_file.write(content)
                        else:
                            logger.error(f"ä¸‹è½½ZIPæ–‡ä»¶å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                            return await self._save_parse_result(original_file_path, result)
            
            # è§£å‹ZIPæ–‡ä»¶
            logger.info(f"æ­£åœ¨è§£å‹ZIPæ–‡ä»¶åˆ°: {output_folder}")
            with zipfile.ZipFile(temp_zip_path, 'r') as zip_ref:
                zip_ref.extractall(output_folder)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(temp_zip_path)
            
            logger.info(f"ZIPæ–‡ä»¶è§£å‹å®Œæˆ: {output_folder}")
            return str(output_folder)
            
        except Exception as e:
            logger.error(f"ä¸‹è½½è§£å‹ZIPæ–‡ä»¶å¤±è´¥: {e}")
            # å¦‚æœä¸‹è½½è§£å‹å¤±è´¥ï¼Œå›é€€åˆ°åŸæ¥çš„ä¿å­˜æ–¹å¼
            return await self._save_parse_result(original_file_path, result)

    async def _save_parse_result(self, original_file_path: str, result: Dict[str, Any]) -> str:
        """ä¿å­˜è§£æç»“æœåˆ°æœ¬åœ°"""
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path("./outputs")
        output_dir.mkdir(exist_ok=True)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        original_name = Path(original_file_path).stem
        timestamp = __import__('datetime').datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = output_dir / f"{original_name}_parsed_{timestamp}.txt"
        
        # æ„å»ºè¾“å‡ºå†…å®¹
        content_lines = []
        content_lines.append(f"æ–‡æ¡£è§£æç»“æœ")
        content_lines.append(f"åŸæ–‡ä»¶: {original_file_path}")
        content_lines.append(f"è§£ææ—¶é—´: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        content_lines.append("=" * 50)
        content_lines.append("")
        
        # æ·»åŠ æ–‡æœ¬å†…å®¹
        if result.get('text'):
            content_lines.append("ğŸ“„ æå–çš„æ–‡æœ¬å†…å®¹:")
            content_lines.append("-" * 30)
            content_lines.append(result['text'])
            content_lines.append("")
        
        # æ·»åŠ è¡¨æ ¼å†…å®¹
        if result.get('tables'):
            content_lines.append("ğŸ“Š æå–çš„è¡¨æ ¼:")
            content_lines.append("-" * 30)
            for i, table in enumerate(result['tables'], 1):
                content_lines.append(f"è¡¨æ ¼ {i}:")
                content_lines.append(str(table))
                content_lines.append("")
        
        # æ·»åŠ å…¬å¼å†…å®¹
        if result.get('formulas'):
            content_lines.append("ğŸ§® æå–çš„å…¬å¼:")
            content_lines.append("-" * 30)
            for i, formula in enumerate(result['formulas'], 1):
                content_lines.append(f"å…¬å¼ {i}: {formula}")
            content_lines.append("")
        
        # å†™å…¥æ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(content_lines))
        
        return str(output_file)
    
    def _get_introduction_response(self, user_input: str) -> str:
        """é¦–æ¬¡ä»‹ç»å“åº”"""
        user_input_lower = user_input.lower().strip()
        
        if any(greeting in user_input_lower for greeting in ['ä½ å¥½', 'hello', 'hi', 'æ‚¨å¥½']):
            return """ä½ å¥½ï¼æˆ‘æ˜¯ä¸“ä¸šçš„æ–‡æ¡£è§£æåŠ©æ‰‹ ğŸ“„

æˆ‘å¯ä»¥å¸®æ‚¨è§£æ PDFã€Wordã€PowerPoint ç­‰æ ¼å¼çš„æ–‡æ¡£ï¼Œæå–å…¶ä¸­çš„æ–‡æœ¬ã€è¡¨æ ¼ã€å…¬å¼ç­‰å†…å®¹ã€‚

è¯·å‘Šè¯‰æˆ‘æ‚¨è¦è§£æä»€ä¹ˆæ–‡æ¡£ï¼Œæˆ–ç›´æ¥æä¾›æ–‡ä»¶è·¯å¾„ï¼"""
        else:
            return """æˆ‘æ˜¯ä¸“ä¸šçš„æ–‡æ¡£è§£æåŠ©æ‰‹ï¼Œå¯ä»¥å¸®æ‚¨è§£æå„ç§æ ¼å¼çš„æ–‡æ¡£ã€‚

è¯·æä¾›æ‚¨è¦è§£æçš„æ–‡ä»¶è·¯å¾„ï¼Œæˆ‘ä¼šä¸ºæ‚¨æå–æ–‡æ¡£ä¸­çš„å†…å®¹ã€‚"""
    
    def _get_contextual_response(self, user_input: str) -> str:
        """åŸºäºä¸Šä¸‹æ–‡çš„å“åº”"""
        user_input_lower = user_input.lower().strip()
        
        if any(word in user_input_lower for word in ['åŠŸèƒ½', 'èƒ½åšä»€ä¹ˆ', 'help', 'å¸®åŠ©']):
            return """æˆ‘å¯ä»¥å¸®æ‚¨ï¼š

ğŸ“„ **æ–‡æ¡£è§£æ**
â€¢ æ”¯æŒ PDFã€Wordã€PowerPoint æ ¼å¼
â€¢ æå–æ–‡æœ¬ã€è¡¨æ ¼ã€å…¬å¼å†…å®¹
â€¢ ä¿æŒåŸå§‹æ–‡æ¡£ç»“æ„

ğŸš€ **ä½¿ç”¨æ–¹æ³•**
ç›´æ¥æä¾›æ–‡ä»¶è·¯å¾„å³å¯ï¼Œä¾‹å¦‚ï¼š
`/Users/ç”¨æˆ·å/Desktop/æ–‡æ¡£.pdf`

ğŸ’¾ **ç»“æœä¿å­˜**
è§£æç»“æœä¼šè‡ªåŠ¨ä¿å­˜åˆ° `./outputs/` ç›®å½•"""
        
        elif any(word in user_input_lower for word in ['æ”¯æŒ', 'æ ¼å¼', 'format']):
            return """ğŸ“‹ **æ”¯æŒçš„æ–‡ä»¶æ ¼å¼**

â€¢ PDF (.pdf) - åŒ…æ‹¬æ‰«æç‰ˆPDFçš„OCRè¯†åˆ«
â€¢ Word (.docx, .doc) - æå–æ–‡æœ¬å’Œè¡¨æ ¼
â€¢ PowerPoint (.pptx, .ppt) - æå–å¹»ç¯ç‰‡å†…å®¹

ğŸŒ **å¤šè¯­è¨€æ”¯æŒ**
â€¢ ä¸­æ–‡ï¼ˆç®€ä½“/ç¹ä½“ï¼‰
â€¢ è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ç­‰"""
        
        else:
            return """è¯·æä¾›æ‚¨è¦è§£æçš„æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ï¼š
â€¢ `/Users/ç”¨æˆ·å/Desktop/æ–‡æ¡£.pdf`
â€¢ `C:\\Documents\\æŠ¥å‘Š.docx`

æˆ–è€…æ‚¨å¯ä»¥è¯¢é—®æˆ‘çš„åŠŸèƒ½å’Œæ”¯æŒçš„æ ¼å¼ã€‚"""
    
    def _get_fallback_response(self, user_input: str) -> str:
        """
        å½“LLMä¸å¯ç”¨æ—¶çš„å›é€€å“åº”ï¼Œå¢å¼ºäº†æ–‡ä»¶è·¯å¾„å’Œæ„å›¾è¯†åˆ«
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            
        Returns:
            str: å›é€€å“åº”
        """
        import re
        
        user_input_lower = user_input.lower().strip()
        
        # æ£€æµ‹æ–‡ä»¶è·¯å¾„æ¨¡å¼ï¼ˆæ”¯æŒåŒ…å«ç©ºæ ¼çš„è·¯å¾„ï¼‰
        file_path_patterns = [
            r"'([^']+\.[a-zA-Z0-9]+)'",  # å•å¼•å·åŒ…å›´çš„è·¯å¾„ '/path/to/file.ext'
            r'"([^"]+\.[a-zA-Z0-9]+)"',  # åŒå¼•å·åŒ…å›´çš„è·¯å¾„ "/path/to/file.ext"
            r'/[^/\n]+(?:/[^/\n]+)*\.[a-zA-Z0-9]+',  # Unixè·¯å¾„ /path/to/file.ext
            r'[A-Za-z]:\\[^\\:\n]+(?:\\[^\\:\n]+)*\.[a-zA-Z0-9]+',  # Windowsè·¯å¾„ C:\path\to\file.ext
            r'[^\s/\\\n]+\.[a-zA-Z0-9]+',  # ç®€å•æ–‡ä»¶å file.ext
        ]
        
        detected_file_path = None
        for i, pattern in enumerate(file_path_patterns):
            match = re.search(pattern, user_input)
            if match:
                # å‰ä¸¤ä¸ªæ¨¡å¼ï¼ˆå¼•å·åŒ…å›´ï¼‰æœ‰åˆ†ç»„ï¼Œä½¿ç”¨group(1)ï¼Œå…¶ä»–ä½¿ç”¨group(0)
                if i < 2:  # å¼•å·åŒ…å›´çš„æ¨¡å¼
                    detected_file_path = match.group(1)
                else:
                    detected_file_path = match.group(0)
                break
        
        # æ£€æµ‹æ–‡ä»¶æ‰©å±•å
        supported_extensions = ['.pdf', '.docx', '.pptx', '.doc', '.ppt']
        detected_extension = None
        for ext in supported_extensions:
            if ext in user_input_lower:
                detected_extension = ext
                break
        
        # æ£€æµ‹è§£æç›¸å…³å…³é”®è¯
        parse_keywords = ['è§£æ', 'parse', 'å¤„ç†', 'process', 'åˆ†æ', 'analyze', 'æå–', 'extract']
        has_parse_intent = any(keyword in user_input_lower for keyword in parse_keywords)
        
        # å¦‚æœæ£€æµ‹åˆ°å…·ä½“æ–‡ä»¶è·¯å¾„ï¼Œæä¾›é’ˆå¯¹æ€§æŒ‡å¯¼
        if detected_file_path:
            file_type = "æ–‡æ¡£"
            if detected_extension:
                if detected_extension == '.pdf':
                    file_type = "PDFæ–‡æ¡£"
                elif detected_extension in ['.docx', '.doc']:
                    file_type = "Wordæ–‡æ¡£"
                elif detected_extension in ['.pptx', '.ppt']:
                    file_type = "PowerPointæ¼”ç¤ºæ–‡ç¨¿"
            
            return f"""æˆ‘çœ‹åˆ°æ‚¨æƒ³è¦è§£æè¿™ä¸ª{file_type}ï¼š
ğŸ“„ **æ–‡ä»¶è·¯å¾„**: `{detected_file_path}`

ğŸ¯ **æ“ä½œæŒ‡å¯¼**
è¦è§£ææ‚¨çš„æ–‡æ¡£ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

1ï¸âƒ£ **è¿”å›ä¸»èœå•**
   è¾“å…¥ 'q' æˆ– 'quit' é€€å‡ºå½“å‰å¯¹è¯

2ï¸âƒ£ **é€‰æ‹©è§£æåŠŸèƒ½**
   åœ¨ä¸»èœå•ä¸­é€‰æ‹© "1" - è§£æå•ä¸ªæ–‡æ¡£

3ï¸âƒ£ **è¾“å…¥æ–‡ä»¶è·¯å¾„**
   å½“ç³»ç»Ÿæç¤ºæ—¶ï¼Œè¾“å…¥æ‚¨çš„æ–‡ä»¶è·¯å¾„ï¼š
   `{detected_file_path}`

4ï¸âƒ£ **ç¡®è®¤æ–‡ä»¶ä¿¡æ¯**
   â€¢ ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®æ— è¯¯
   â€¢ ç¡®è®¤æ–‡ä»¶å­˜åœ¨ä¸”å¯è®¿é—®
   â€¢ æ”¯æŒçš„æ ¼å¼ï¼šPDFã€Word(.docx)ã€PowerPoint(.pptx)

ğŸ’¡ **æç¤º**
â€¢ å¦‚æœè·¯å¾„åŒ…å«ç©ºæ ¼ï¼Œè¯·ç¡®ä¿è·¯å¾„æ ¼å¼æ­£ç¡®
â€¢ ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹æ–‡æ¡£è¯­è¨€å¹¶è¿›è¡ŒOCRè¯†åˆ«
â€¢ è§£æå®Œæˆåä¼šæ˜¾ç¤ºæå–çš„æ–‡æœ¬ã€è¡¨æ ¼ç­‰å†…å®¹

ğŸ”§ **æ•…éšœæ’é™¤**
å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
â€¢ æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
â€¢ æ–‡ä»¶æ˜¯å¦å­˜åœ¨
â€¢ æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ
â€¢ æ–‡ä»¶æ˜¯å¦æŸåæˆ–åŠ å¯†"""

        # é—®å€™è¯­
        elif any(greeting in user_input_lower for greeting in ['ä½ å¥½', 'hello', 'hi', 'æ‚¨å¥½']):
            return """ä½ å¥½ï¼æˆ‘æ˜¯ä¸“ä¸šçš„æ–‡æ¡£è§£æåŠ©æ‰‹ ğŸ“„

æˆ‘å¯ä»¥å¸®åŠ©æ‚¨ï¼š
â€¢ è§£æPDFã€Wordã€PPTç­‰æ–‡æ¡£
â€¢ æå–æ–‡æœ¬ã€è¡¨æ ¼ã€å…¬å¼å’Œå›¾ç‰‡
â€¢ åˆ†ææ–‡æ¡£ç»“æ„å’Œå…ƒæ•°æ®
â€¢ æŸ¥è¯¢æ”¯æŒçš„OCRè¯­è¨€

è¯·è¿”å›ä¸»èœå•é€‰æ‹©ç›¸åº”åŠŸèƒ½ï¼Œæˆ–è€…å‘Šè¯‰æˆ‘æ‚¨æƒ³è¦è§£æä»€ä¹ˆç±»å‹çš„æ–‡æ¡£ï¼"""

        # åŠŸèƒ½è¯¢é—®
        elif any(word in user_input_lower for word in ['èƒ½åšä»€ä¹ˆ', 'åŠŸèƒ½', 'å¸®åŠ©', 'help', 'åšä»€ä¹ˆ']):
            return """æˆ‘æ˜¯ä¸“ä¸šçš„æ–‡æ¡£è§£æåŠ©æ‰‹ï¼Œå…·å¤‡ä»¥ä¸‹åŠŸèƒ½ï¼š

ğŸ” **æ–‡æ¡£è§£æ**
â€¢ æ”¯æŒPDFã€Wordã€PPTç­‰æ ¼å¼
â€¢ æ™ºèƒ½æå–æ–‡æœ¬ã€è¡¨æ ¼ã€å…¬å¼
â€¢ ä¿æŒåŸå§‹æ–‡æ¡£ç»“æ„

ğŸ“Š **å†…å®¹åˆ†æ**
â€¢ æ–‡æ¡£ç»“æ„åˆ†æ
â€¢ å…ƒæ•°æ®æå–
â€¢ å¤šè¯­è¨€OCRæ”¯æŒ

ğŸ’¡ **ä½¿ç”¨å»ºè®®**
è¯·è¿”å›ä¸»èœå•é€‰æ‹©åŠŸèƒ½é€‰é¡¹ï¼š
1ï¸âƒ£ è§£æå•ä¸ªæ–‡æ¡£
2ï¸âƒ£ è§£æç¤ºä¾‹PDF
3ï¸âƒ£ æŸ¥çœ‹æ”¯æŒè¯­è¨€"""

        # æ–‡æ¡£è§£æç›¸å…³ï¼ˆä½†æ²¡æœ‰å…·ä½“æ–‡ä»¶è·¯å¾„ï¼‰
        elif has_parse_intent or any(word in user_input_lower for word in ['pdf', 'word', 'ppt', 'æ–‡æ¡£']):
            return """æˆ‘å¯ä»¥å¸®æ‚¨è§£æå„ç§æ ¼å¼çš„æ–‡æ¡£ï¼ğŸ“„

ğŸ¯ **æ”¯æŒæ ¼å¼**
â€¢ PDFæ–‡æ¡£ (.pdf)
â€¢ Wordæ–‡æ¡£ (.docx, .doc)
â€¢ PowerPointæ¼”ç¤ºæ–‡ç¨¿ (.pptx, .ppt)

ğŸš€ **å¿«é€Ÿå¼€å§‹**
1ï¸âƒ£ **æœ‰å…·ä½“æ–‡ä»¶è¦è§£æï¼Ÿ**
   è¿”å›ä¸»èœå•é€‰æ‹©"é€‰é¡¹1ï¼šè§£æå•ä¸ªæ–‡æ¡£"
   ç„¶åè¾“å…¥æ‚¨çš„æ–‡ä»¶è·¯å¾„

2ï¸âƒ£ **æƒ³å…ˆè¯•ç”¨åŠŸèƒ½ï¼Ÿ**
   è¿”å›ä¸»èœå•é€‰æ‹©"é€‰é¡¹2ï¼šè§£æç¤ºä¾‹PDF"

ğŸ’¡ **ä½¿ç”¨æç¤º**
â€¢ æ”¯æŒä¸­è‹±æ–‡ç­‰å¤šè¯­è¨€OCR
â€¢ è‡ªåŠ¨æå–æ–‡æœ¬ã€è¡¨æ ¼ã€å…¬å¼
â€¢ ä¿æŒåŸå§‹æ–‡æ¡£ç»“æ„å’Œæ ¼å¼
â€¢ å¯æŒ‡å®šé¡µé¢èŒƒå›´è¿›è¡Œè§£æ

ğŸ“ **æ–‡ä»¶è·¯å¾„æ ¼å¼ç¤ºä¾‹**
â€¢ macOS/Linux: `/Users/ç”¨æˆ·å/Documents/æ–‡ä»¶.pdf`
â€¢ Windows: `C:\\Users\\ç”¨æˆ·å\\Documents\\æ–‡ä»¶.pdf`"""

        # è¯­è¨€æ”¯æŒè¯¢é—®
        elif any(word in user_input_lower for word in ['è¯­è¨€', 'language', 'æ”¯æŒ', 'ocr']):
            return """æˆ‘æ”¯æŒå¤šç§è¯­è¨€çš„OCRè¯†åˆ«ï¼ğŸŒ

ğŸ“ **ä¸»è¦æ”¯æŒè¯­è¨€**
â€¢ ä¸­æ–‡ï¼ˆç®€ä½“/ç¹ä½“ï¼‰
â€¢ è‹±æ–‡
â€¢ æ—¥æ–‡
â€¢ éŸ©æ–‡
â€¢ ä»¥åŠæ›´å¤šè¯­è¨€...

ğŸ” **æŸ¥çœ‹å®Œæ•´åˆ—è¡¨**
è¯·è¿”å›ä¸»èœå•é€‰æ‹©"é€‰é¡¹3ï¼šæŸ¥çœ‹æ”¯æŒè¯­è¨€"è·å–è¯¦ç»†çš„è¯­è¨€æ”¯æŒåˆ—è¡¨ã€‚

ğŸ’¡ **è‡ªåŠ¨æ£€æµ‹**ï¼šç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹æ–‡æ¡£è¯­è¨€ï¼Œæ‚¨ä¹Ÿå¯ä»¥æ‰‹åŠ¨æŒ‡å®šã€‚"""

        # é»˜è®¤å›å¤
        else:
            return """æ„Ÿè°¢æ‚¨çš„æé—®ï¼æˆ‘æ˜¯ä¸“ä¸šçš„æ–‡æ¡£è§£æåŠ©æ‰‹ ğŸ¤–

æˆ‘å¯ä»¥å¸®åŠ©æ‚¨å¤„ç†å„ç§æ–‡æ¡£è§£æéœ€æ±‚ã€‚å¦‚æœæ‚¨æƒ³äº†è§£å…·ä½“åŠŸèƒ½ï¼Œè¯·è¿”å›ä¸»èœå•é€‰æ‹©ç›¸åº”çš„é€‰é¡¹ï¼š

ğŸ“‹ **åŠŸèƒ½èœå•**
1ï¸âƒ£ è§£æå•ä¸ªæ–‡æ¡£
2ï¸âƒ£ è§£æç¤ºä¾‹PDF  
3ï¸âƒ£ æŸ¥çœ‹æ”¯æŒè¯­è¨€

ğŸ’¡ **æ™ºèƒ½æç¤º**
å¦‚æœæ‚¨æœ‰å…·ä½“çš„æ–‡ä»¶è¦è§£æï¼Œå¯ä»¥ç›´æ¥å‘Šè¯‰æˆ‘æ–‡ä»¶è·¯å¾„ï¼Œæˆ‘ä¼šä¸ºæ‚¨æä¾›è¯¦ç»†çš„æ“ä½œæŒ‡å¯¼ï¼

ä¾‹å¦‚ï¼š
â€¢ "æˆ‘æƒ³è§£æ /Users/ç”¨æˆ·å/Documents/æŠ¥å‘Š.pdf"
â€¢ "è¯·å¸®æˆ‘å¤„ç†è¿™ä¸ªæ–‡ä»¶ï¼šC:\\Documents\\presentation.pptx"

æˆ‘ä¼šæ ¹æ®æ‚¨çš„å…·ä½“éœ€æ±‚æä¾›é’ˆå¯¹æ€§çš„å¸®åŠ©ï¼"""
    
    def _initialize_llm(self):
        """åˆå§‹åŒ–LLM"""
        try:
            from agenticx.llms.bailian_provider import BailianProvider
            from agenticx.llms.kimi_provider import KimiProvider
            
            # è·å–LLMé…ç½®
            config = self.memory_config.get("config", {})
            llm_config = config.get("llm", {})
            
            provider = llm_config.get("provider", "bailian")
            
            if provider == "bailian":
                self._llm = BailianProvider(
                    model=llm_config.get("model", "qwen3-max"),
                    api_key=llm_config.get("api_key"),
                    base_url=llm_config.get("base_url"),
                    temperature=llm_config.get("temperature", 0.7),
                    max_tokens=llm_config.get("max_tokens", 4000)
                )
            elif provider == "kimi":
                self._llm = KimiProvider(
                    model=llm_config.get("model", "moonshot-v1-8k"),
                    api_key=llm_config.get("api_key"),
                    temperature=llm_config.get("temperature", 0.7),
                    max_tokens=llm_config.get("max_tokens", 4000)
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„LLMæä¾›å•†: {provider}")
            
            logger.info(f"LLMåˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æä¾›å•†: {provider}")
            
        except Exception as e:
            logger.error(f"LLMåˆå§‹åŒ–å¤±è´¥: {e}")
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„å›é€€LLM
            self._llm = self._create_fallback_llm()
    
    def _create_fallback_llm(self):
        """åˆ›å»ºå›é€€LLMï¼ˆç®€å•çš„è§„åˆ™å“åº”ï¼‰"""
        class FallbackLLM:
            async def achat(self, messages):
                user_message = messages[-1]["content"].lower()
                
                if any(keyword in user_message for keyword in ["ä½ å¥½", "hello", "hi"]):
                    return type('Response', (), {'content': "æ‚¨å¥½ï¼æˆ‘æ˜¯æ–‡æ¡£è§£æåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼æˆ‘å¯ä»¥å¸®æ‚¨è§£æPDFã€Wordã€PPTç­‰æ–‡æ¡£ï¼Œæå–å…¶ä¸­çš„æ–‡æœ¬ã€è¡¨æ ¼ã€å…¬å¼å’Œå›¾ç‰‡ã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"})()
                elif any(keyword in user_message for keyword in ["è§£æ", "parse", "æ–‡æ¡£", "document"]):
                    return type('Response', (), {'content': "æˆ‘å¯ä»¥å¸®æ‚¨è§£æå„ç§æ ¼å¼çš„æ–‡æ¡£ï¼è¯·é€‰æ‹©ä¸»èœå•ä¸­çš„\"è§£æå•ä¸ªæ–‡æ¡£\"æˆ–\"è§£æç¤ºä¾‹PDF\"åŠŸèƒ½ï¼Œæˆ‘ä¼šå¼•å¯¼æ‚¨å®Œæˆæ•´ä¸ªè§£æè¿‡ç¨‹ã€‚"})()
                elif any(keyword in user_message for keyword in ["æ”¯æŒ", "è¯­è¨€", "language"]):
                    return type('Response', (), {'content': "æˆ‘æ”¯æŒå¤šç§OCRè¯­è¨€ï¼ŒåŒ…æ‹¬ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ç­‰ã€‚æ‚¨å¯ä»¥é€‰æ‹©ä¸»èœå•ä¸­çš„\"æŸ¥çœ‹æ”¯æŒè¯­è¨€\"åŠŸèƒ½æ¥æŸ¥çœ‹å®Œæ•´çš„è¯­è¨€åˆ—è¡¨ã€‚"})()
                elif any(keyword in user_message for keyword in ["å¸®åŠ©", "help", "åŠŸèƒ½"]):
                    return type('Response', (), {'content': "æˆ‘æä¾›ä»¥ä¸‹ä¸»è¦åŠŸèƒ½ï¼š\n1. è§£æPDFã€Wordã€PPTç­‰æ–‡æ¡£\n2. æå–æ–‡æœ¬ã€è¡¨æ ¼ã€å…¬å¼å’Œå›¾ç‰‡\n3. åˆ†ææ–‡æ¡£ç»“æ„\n4. è·å–æ–‡æ¡£å…ƒæ•°æ®\n5. æ”¯æŒå¤šç§OCRè¯­è¨€\n\nè¯·è¿”å›ä¸»èœå•é€‰æ‹©ç›¸åº”çš„åŠŸèƒ½é€‰é¡¹ï¼"})()
                else:
                    return type('Response', (), {'content': "æ„Ÿè°¢æ‚¨çš„æé—®ï¼æˆ‘æ˜¯ä¸“ä¸šçš„æ–‡æ¡£è§£æåŠ©æ‰‹ï¼Œå¯ä»¥å¸®æ‚¨å¤„ç†å„ç§æ–‡æ¡£è§£æéœ€æ±‚ã€‚å¦‚æœæ‚¨æƒ³äº†è§£å…·ä½“åŠŸèƒ½ï¼Œè¯·è¿”å›ä¸»èœå•é€‰æ‹©ç›¸åº”çš„é€‰é¡¹ï¼Œæˆ–è€…ç›´æ¥å‘Šè¯‰æˆ‘æ‚¨æƒ³è¦è§£æä»€ä¹ˆç±»å‹çš„æ–‡æ¡£ã€‚"})()
        
        return FallbackLLM()


# å¯¼å‡ºä¸»è¦ç±»
__all__ = [
    "DocumentParserAgent",
    "ParseDocumentTool",
    "GetSupportedLanguagesTool",
    "AnalyzeDocumentStructureTool",
    "ExtractDocumentMetadataTool"
]