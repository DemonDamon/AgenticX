"""
AgenticX M5 å¤šæ™ºèƒ½ä½“åä½œæ¼”ç¤º

è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº† M5 æ¨¡å—çš„å¤šæ™ºèƒ½ä½“åä½œåŠŸèƒ½ï¼š
- å¤šä¸ªæ™ºèƒ½ä½“ååŒå·¥ä½œ
- æ™ºèƒ½ä½“é—´é€šä¿¡å’Œåè°ƒ
- ä»»åŠ¡åˆ†è§£å’Œå¹¶è¡Œæ‰§è¡Œ
- ç»“æœèšåˆå’Œæ•´åˆ

æ¼”ç¤ºåœºæ™¯ï¼šæ•°æ®åˆ†æå›¢é˜Ÿåä½œå®Œæˆæ•°æ®å¤„ç†ä»»åŠ¡
"""

import sys
import os
import json
import asyncio
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from agenticx.core import (
    Agent, Task, tool, AgentExecutor, PromptManager, 
    ErrorHandler, CommunicationInterface, BroadcastCommunication
)
from agenticx.llms.base import BaseLLMProvider
from agenticx.llms.response import LLMResponse, TokenUsage


class MockLLMProvider(BaseLLMProvider):
    """Mock LLM provider for demonstration."""
    
    def __init__(self, responses=None, agent_name="default"):
        super().__init__(model=f"mock-model-{agent_name}")
        object.__setattr__(self, 'responses', responses or [])
        object.__setattr__(self, 'call_count', 0)
        object.__setattr__(self, 'agent_name', agent_name)
    
    def invoke(self, prompt: str, **kwargs) -> LLMResponse:
        if self.call_count < len(self.responses):
            content = self.responses[self.call_count]
        else:
            content = f'{{"action": "finish_task", "result": "ä»»åŠ¡å®Œæˆ - {self.agent_name}", "reasoning": "é»˜è®¤å®Œæˆ"}}'
        
        object.__setattr__(self, 'call_count', self.call_count + 1)
        
        return LLMResponse(
            id=f"mock-response-{self.agent_name}-{self.call_count}",
            model_name=self.model,
            created=1234567890,
            content=content,
            choices=[],
            token_usage=TokenUsage(prompt_tokens=10, completion_tokens=20, total_tokens=30),
            cost=0.001
        )
    
    async def ainvoke(self, prompt: str, **kwargs) -> LLMResponse:
        return self.invoke(prompt, **kwargs)
    
    def stream(self, prompt: str, **kwargs):
        response = self.invoke(prompt, **kwargs)
        yield response.content
    
    async def astream(self, prompt: str, **kwargs):
        response = await self.ainvoke(prompt, **kwargs)
        yield response.content


# æ•°æ®å¤„ç†å·¥å…·
@tool()
def load_data(data_source: str) -> Dict[str, Any]:
    """åŠ è½½æ•°æ®æº"""
    # æ¨¡æ‹Ÿæ•°æ®åŠ è½½
    mock_data = {
        "sales": [100, 150, 200, 175, 225, 300, 250],
        "customers": ["Alice", "Bob", "Charlie", "Diana", "Eve", "Frank", "Grace"],
        "dates": ["2024-01-01", "2024-01-02", "2024-01-03", "2024-01-04", "2024-01-05", "2024-01-06", "2024-01-07"],
        "source": data_source
    }
    return mock_data


@tool()
def calculate_statistics(data: List[float]) -> Dict[str, float]:
    """è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡"""
    if not data:
        return {"error": "æ•°æ®ä¸ºç©º"}
    
    return {
        "mean": sum(data) / len(data),
        "max": max(data),
        "min": min(data),
        "total": sum(data),
        "count": len(data)
    }


@tool()
def filter_data(data: List[Any], condition: str, value: Any) -> List[Any]:
    """æ ¹æ®æ¡ä»¶è¿‡æ»¤æ•°æ®"""
    # ç®€å•çš„è¿‡æ»¤é€»è¾‘
    if condition == "greater_than":
        return [x for x in data if isinstance(x, (int, float)) and x > value]
    elif condition == "less_than":
        return [x for x in data if isinstance(x, (int, float)) and x < value]
    elif condition == "equals":
        return [x for x in data if x == value]
    else:
        return data


@tool()
def generate_report(title: str, data: Dict[str, Any]) -> str:
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    report = f"# {title}\n\n"
    report += "## æ•°æ®åˆ†æç»“æœ\n\n"
    
    for key, value in data.items():
        if isinstance(value, dict):
            report += f"### {key}\n"
            for sub_key, sub_value in value.items():
                report += f"- {sub_key}: {sub_value}\n"
        else:
            report += f"- {key}: {value}\n"
    
    report += "\n---\næŠ¥å‘Šç”Ÿæˆæ—¶é—´: 2024-01-07\n"
    
    # ä¿å­˜æŠ¥å‘Š
    with open(f"{title.lower().replace(' ', '_')}_report.md", "w", encoding="utf-8") as f:
        f.write(report)
    
    return f"æŠ¥å‘Šå·²ç”Ÿæˆå¹¶ä¿å­˜ä¸º {title.lower().replace(' ', '_')}_report.md"


@tool()
def send_team_message(recipient: str, message: str, message_type: str = "info") -> str:
    """å‘å›¢é˜Ÿæˆå‘˜å‘é€æ¶ˆæ¯"""
    return f"æ¶ˆæ¯å·²å‘é€ç»™ {recipient}: {message} (ç±»å‹: {message_type})"


def create_data_analyst() -> Agent:
    """åˆ›å»ºæ•°æ®åˆ†æå¸ˆæ™ºèƒ½ä½“"""
    return Agent(
        name="DataAnalyst",
        role="æ•°æ®åˆ†æå¸ˆ",
        goal="åˆ†ææ•°æ®å¹¶æå–æœ‰ä»·å€¼çš„æ´å¯Ÿ",
        backstory="æˆ‘æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿ç»Ÿè®¡åˆ†æå’Œæ•°æ®è§£è¯»",
        organization_id="data_team"
    )


def create_data_engineer() -> Agent:
    """åˆ›å»ºæ•°æ®å·¥ç¨‹å¸ˆæ™ºèƒ½ä½“"""
    return Agent(
        name="DataEngineer", 
        role="æ•°æ®å·¥ç¨‹å¸ˆ",
        goal="å¤„ç†å’Œæ¸…æ´—æ•°æ®ï¼Œç¡®ä¿æ•°æ®è´¨é‡",
        backstory="æˆ‘æ˜¯æ•°æ®å·¥ç¨‹å¸ˆï¼Œè´Ÿè´£æ•°æ®ç®¡é“å’Œæ•°æ®è´¨é‡ä¿è¯",
        organization_id="data_team"
    )


def create_report_writer() -> Agent:
    """åˆ›å»ºæŠ¥å‘Šæ’°å†™å‘˜æ™ºèƒ½ä½“"""
    return Agent(
        name="ReportWriter",
        role="æŠ¥å‘Šæ’°å†™å‘˜", 
        goal="æ’°å†™æ¸…æ™°çš„åˆ†ææŠ¥å‘Šå’Œæ€»ç»“",
        backstory="æˆ‘ä¸“é—¨è´Ÿè´£å°†æŠ€æœ¯åˆ†æç»“æœè½¬åŒ–ä¸ºæ˜“æ‡‚çš„å•†ä¸šæŠ¥å‘Š",
        organization_id="data_team"
    )


def create_team_coordinator() -> Agent:
    """åˆ›å»ºå›¢é˜Ÿåè°ƒå‘˜æ™ºèƒ½ä½“"""
    return Agent(
        name="TeamCoordinator",
        role="å›¢é˜Ÿåè°ƒå‘˜",
        goal="åè°ƒå›¢é˜Ÿå·¥ä½œï¼Œç¡®ä¿ä»»åŠ¡é¡ºåˆ©å®Œæˆ", 
        backstory="æˆ‘è´Ÿè´£åè°ƒå›¢é˜Ÿæˆå‘˜ä¹‹é—´çš„å·¥ä½œï¼Œç¡®ä¿é¡¹ç›®æŒ‰æ—¶å®Œæˆ",
        organization_id="data_team"
    )


async def run_multi_agent_demo():
    """è¿è¡Œå¤šæ™ºèƒ½ä½“åä½œæ¼”ç¤º"""
    print("ğŸš€ AgenticX M5 å¤šæ™ºèƒ½ä½“åä½œæ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agents = {
        "analyst": create_data_analyst(),
        "engineer": create_data_engineer(), 
        "writer": create_report_writer(),
        "coordinator": create_team_coordinator()
    }
    
    print("ğŸ¤– åˆ›å»ºæ™ºèƒ½ä½“å›¢é˜Ÿ:")
    for role, agent in agents.items():
        print(f"  â€¢ {agent.name} ({agent.role})")
    
    # åˆ›å»º LLM æä¾›è€…ï¼ˆä¸ºæ¯ä¸ªæ™ºèƒ½ä½“å®šåˆ¶å“åº”ï¼‰
    llm_providers = {
        "analyst": MockLLMProvider([
            '{"action": "tool_call", "tool": "load_data", "args": {"data_source": "sales_database"}, "reasoning": "é¦–å…ˆåŠ è½½é”€å”®æ•°æ®"}',
            '{"action": "tool_call", "tool": "calculate_statistics", "args": {"data": [100, 150, 200, 175, 225, 300, 250]}, "reasoning": "è®¡ç®—é”€å”®æ•°æ®çš„ç»Ÿè®¡æŒ‡æ ‡"}',
            '{"action": "tool_call", "tool": "send_team_message", "args": {"recipient": "ReportWriter", "message": "æ•°æ®åˆ†æå®Œæˆï¼Œå¹³å‡é”€å”®é¢ä¸º200ï¼Œæ€»é”€å”®é¢ä¸º1400", "message_type": "analysis_result"}, "reasoning": "å‘æŠ¥å‘Šæ’°å†™å‘˜å‘é€åˆ†æç»“æœ"}',
            '{"action": "finish_task", "result": "æ•°æ®åˆ†æå®Œæˆï¼šå¹³å‡é”€å”®é¢200ï¼Œæœ€é«˜300ï¼Œæœ€ä½100ï¼Œæ€»è®¡1400", "reasoning": "åˆ†æä»»åŠ¡å®Œæˆ"}'
        ], "DataAnalyst"),
        
        "engineer": MockLLMProvider([
            '{"action": "tool_call", "tool": "filter_data", "args": {"data": [100, 150, 200, 175, 225, 300, 250], "condition": "greater_than", "value": 180}, "reasoning": "è¿‡æ»¤å‡ºé«˜äº180çš„é”€å”®æ•°æ®"}',
            '{"action": "tool_call", "tool": "send_team_message", "args": {"recipient": "DataAnalyst", "message": "æ•°æ®æ¸…æ´—å®Œæˆï¼Œé«˜ä»·å€¼é”€å”®è®°å½•ï¼š[200, 225, 300, 250]", "message_type": "data_ready"}, "reasoning": "é€šçŸ¥åˆ†æå¸ˆæ•°æ®å·²å‡†å¤‡å¥½"}',
            '{"action": "finish_task", "result": "æ•°æ®å·¥ç¨‹ä»»åŠ¡å®Œæˆï¼šæ¸…æ´—å¹¶è¿‡æ»¤äº†é”€å”®æ•°æ®", "reasoning": "å·¥ç¨‹ä»»åŠ¡å®Œæˆ"}'
        ], "DataEngineer"),
        
        "writer": MockLLMProvider([
            '{"action": "tool_call", "tool": "generate_report", "args": {"title": "Sales Analysis Report", "data": {"statistics": {"mean": 200, "max": 300, "min": 100, "total": 1400}, "high_value_sales": [200, 225, 300, 250]}}, "reasoning": "ç”Ÿæˆé”€å”®åˆ†ææŠ¥å‘Š"}',
            '{"action": "tool_call", "tool": "send_team_message", "args": {"recipient": "TeamCoordinator", "message": "é”€å”®åˆ†ææŠ¥å‘Šå·²å®Œæˆå¹¶ä¿å­˜", "message_type": "report_complete"}, "reasoning": "é€šçŸ¥åè°ƒå‘˜æŠ¥å‘Šå®Œæˆ"}',
            '{"action": "finish_task", "result": "é”€å”®åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆå¹¶ä¿å­˜ä¸º sales_analysis_report.md", "reasoning": "æŠ¥å‘Šæ’°å†™å®Œæˆ"}'
        ], "ReportWriter"),
        
        "coordinator": MockLLMProvider([
            '{"action": "tool_call", "tool": "send_team_message", "args": {"recipient": "DataEngineer", "message": "è¯·å¼€å§‹æ•°æ®æ¸…æ´—å·¥ä½œ", "message_type": "task_assignment"}, "reasoning": "åˆ†é…æ•°æ®æ¸…æ´—ä»»åŠ¡"}',
            '{"action": "tool_call", "tool": "send_team_message", "args": {"recipient": "DataAnalyst", "message": "æ•°æ®å‡†å¤‡å°±ç»ªï¼Œè¯·å¼€å§‹åˆ†æ", "message_type": "task_assignment"}, "reasoning": "åˆ†é…æ•°æ®åˆ†æä»»åŠ¡"}',
            '{"action": "finish_task", "result": "å›¢é˜Ÿåè°ƒå®Œæˆï¼šæ‰€æœ‰ä»»åŠ¡å·²åˆ†é…å¹¶ç›‘æ§è¿›åº¦", "reasoning": "åè°ƒä»»åŠ¡å®Œæˆ"}'
        ], "TeamCoordinator")
    }
    
    # åˆ›å»ºå·¥å…·åˆ—è¡¨
    tools = [load_data, calculate_statistics, filter_data, generate_report, send_team_message]
    print(f"ğŸ”§ å¯ç”¨å·¥å…·: {[tool.name for tool in tools]}")
    
    # åˆ›å»ºä»»åŠ¡
    tasks = {
        "coordinator": Task(
            description="åè°ƒå›¢é˜Ÿå®Œæˆé”€å”®æ•°æ®åˆ†æé¡¹ç›®ï¼Œåˆ†é…ä»»åŠ¡å¹¶ç›‘æ§è¿›åº¦",
            expected_output="å›¢é˜Ÿåè°ƒå®Œæˆï¼Œæ‰€æœ‰æˆå‘˜æ”¶åˆ°ä»»åŠ¡åˆ†é…"
        ),
        "engineer": Task(
            description="æ¸…æ´—å’Œé¢„å¤„ç†é”€å”®æ•°æ®ï¼Œè¿‡æ»¤å‡ºé«˜ä»·å€¼é”€å”®è®°å½•",
            expected_output="æ¸…æ´—åçš„é«˜è´¨é‡æ•°æ®é›†"
        ),
        "analyst": Task(
            description="åˆ†æé”€å”®æ•°æ®ï¼Œè®¡ç®—å…³é”®ç»Ÿè®¡æŒ‡æ ‡å’Œè¶‹åŠ¿",
            expected_output="è¯¦ç»†çš„æ•°æ®åˆ†æç»“æœå’Œæ´å¯Ÿ"
        ),
        "writer": Task(
            description="åŸºäºåˆ†æç»“æœæ’°å†™ä¸“ä¸šçš„é”€å”®åˆ†ææŠ¥å‘Š",
            expected_output="å®Œæ•´çš„é”€å”®åˆ†ææŠ¥å‘Šæ–‡æ¡£"
        )
    }
    
    # åˆ›å»ºé€šä¿¡ç³»ç»Ÿ
    communications = {}
    for role, agent in agents.items():
        comm = BroadcastCommunication(agent.id)
        comm.join_group("data_team")
        communications[role] = comm
    
    # åˆ›å»ºæ‰§è¡Œå™¨
    executors = {}
    for role, agent in agents.items():
        executor = AgentExecutor(
            llm_provider=llm_providers[role],
            tools=tools,
            prompt_manager=PromptManager(),
            error_handler=ErrorHandler(max_consecutive_errors=2),
            communication=communications[role],
            max_iterations=10
        )
        executors[role] = executor
    
    print("\nğŸ¯ å¼€å§‹å¤šæ™ºèƒ½ä½“åä½œ...")
    print("-" * 60)
    
    # å¹¶è¡Œæ‰§è¡Œä»»åŠ¡
    results = {}
    
    async def execute_agent_task(role, agent, task, executor):
        print(f"ğŸƒ {agent.name} å¼€å§‹æ‰§è¡Œä»»åŠ¡...")
        result = executor.run(agent, task)
        print(f"âœ… {agent.name} ä»»åŠ¡å®Œæˆ!")
        return role, result
    
    # åˆ›å»ºå¹¶å‘ä»»åŠ¡
    agent_tasks = []
    for role, agent in agents.items():
        task = tasks[role]
        executor = executors[role]
        agent_tasks.append(execute_agent_task(role, agent, task, executor))
    
    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æ™ºèƒ½ä½“ä»»åŠ¡
    completed_tasks = await asyncio.gather(*agent_tasks)
    
    # æ”¶é›†ç»“æœ
    for role, result in completed_tasks:
        results[role] = result
    
    print("\nğŸ“Š å¤šæ™ºèƒ½ä½“åä½œç»“æœ:")
    print("-" * 60)
    
    total_success = 0
    total_events = 0
    total_tools = 0
    total_llm_calls = 0
    total_cost = 0.0
    
    for role, result in results.items():
        agent_name = agents[role].name
        success = "âœ… æˆåŠŸ" if result["success"] else "âŒ å¤±è´¥"
        print(f"\nğŸ¤– {agent_name} ({role}):")
        print(f"  çŠ¶æ€: {success}")
        print(f"  ç»“æœ: {result['result']}")
        
        stats = result["stats"]
        print(f"  äº‹ä»¶æ•°: {stats['total_events']}")
        print(f"  å·¥å…·è°ƒç”¨: {stats['tool_calls']}")
        print(f"  LLMè°ƒç”¨: {stats['llm_calls']}")
        print(f"  æˆæœ¬: ${stats['estimated_cost']:.4f}")
        
        if result["success"]:
            total_success += 1
        total_events += stats['total_events']
        total_tools += stats['tool_calls']
        total_llm_calls += stats['llm_calls']
        total_cost += stats['estimated_cost']
    
    print(f"\nğŸ“ˆ å›¢é˜Ÿæ€»ä½“ç»Ÿè®¡:")
    print(f"  æˆåŠŸç‡: {total_success}/{len(agents)} ({total_success/len(agents)*100:.1f}%)")
    print(f"  æ€»äº‹ä»¶æ•°: {total_events}")
    print(f"  æ€»å·¥å…·è°ƒç”¨: {total_tools}")
    print(f"  æ€»LLMè°ƒç”¨: {total_llm_calls}")
    print(f"  æ€»æˆæœ¬: ${total_cost:.4f}")
    
    # æ˜¾ç¤ºé€šä¿¡ç»Ÿè®¡
    print(f"\nğŸ’¬ å›¢é˜Ÿé€šä¿¡ç»Ÿè®¡:")
    total_messages = 0
    for role, comm in communications.items():
        stats = comm.get_message_stats()
        agent_name = agents[role].name
        print(f"  {agent_name}: å‘é€{stats['sent_count']} æ¥æ”¶{stats['received_count']}")
        total_messages += stats['sent_count']
    
    print(f"  å›¢é˜Ÿæ€»æ¶ˆæ¯æ•°: {total_messages}")
    
    # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
    print(f"\nğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶:")
    if os.path.exists("sales_analysis_report.md"):
        print("  âœ… sales_analysis_report.md - é”€å”®åˆ†ææŠ¥å‘Š")
        with open("sales_analysis_report.md", "r", encoding="utf-8") as f:
            content = f.read()
            print(f"     æŠ¥å‘Šé•¿åº¦: {len(content)} å­—ç¬¦")
    else:
        print("  âŒ æœªæ‰¾åˆ°ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶")
    
    print("\nğŸ‰ å¤šæ™ºèƒ½ä½“åä½œæ¼”ç¤ºå®Œæˆ!")


if __name__ == "__main__":
    asyncio.run(run_multi_agent_demo()) 