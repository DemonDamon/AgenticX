# Refly.AI æ ¸å¿ƒæŠ€æœ¯æ¶æ„æ·±åº¦åˆ†æ

åŸºäºå¯¹ Refly å¼€æºé¡¹ç›®æºç çš„æ·±å…¥ç ”ç©¶ï¼Œæœ¬æ–‡æ¡£æç‚¼å‡º 10 ä¸ªæ ¸å¿ƒæŠ€æœ¯é—®é¢˜åŠå…¶å®ç°ç»†èŠ‚ã€‚

## é¡¹ç›®æ¦‚è§ˆ

Refly.AI æ˜¯å…¨çƒé¦–ä¸ª **Vibe Workflow Platform**ï¼ˆæ°›å›´å·¥ä½œæµå¹³å°ï¼‰ï¼Œä¸“ä¸ºéæŠ€æœ¯åˆ›ä½œè€…è®¾è®¡ï¼Œé€šè¿‡å¯è§†åŒ– Canvas å’Œæ™ºèƒ½ç¼–æ’å®ç° AI è‡ªåŠ¨åŒ–å·¥ä½œæµã€‚

**æŠ€æœ¯æ ˆ:**
- **æ¶æ„:** Monorepo (Turborepo)
- **å‰ç«¯:** React + TypeScript + Tailwind CSS + @xyflow/react (å¯è§†åŒ–æµç¨‹å›¾)
- **åç«¯:** NestJS + Prisma + PostgreSQL
- **æ¶ˆæ¯é˜Ÿåˆ—:** BullMQ + Redis
- **AIæ¡†æ¶:** LangChain + LangGraph
- **å‘é‡å­˜å‚¨:** æ”¯æŒå¤šç§å‘é‡æ•°æ®åº“
- **æµè§ˆå™¨æ‰©å±•:** WXTæ¡†æ¶

---

## æ ¸å¿ƒæŠ€æœ¯é—®é¢˜æ·±åº¦è§£æ

### 1. æ•´ä½“æŠ€æœ¯æ¶æ„è®¾è®¡ï¼šå¦‚ä½•å®ç°å‰åç«¯ååŒçš„å·¥ä½œæµå¼•æ“ï¼Ÿ

#### æ¶æ„å±‚æ¬¡åˆ’åˆ†

**1.1 åŒ…ç»“æ„è®¾è®¡ (Monorepo)**

```
refly/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ api/              # NestJS åç«¯æœåŠ¡ (æ ¸å¿ƒå¼•æ“)
â”‚   â”œâ”€â”€ web/              # React å‰ç«¯åº”ç”¨ (Canvasç¼–è¾‘å™¨)
â”‚   â””â”€â”€ extension/        # æµè§ˆå™¨æ‰©å±• (å†…å®¹æŠ“å–)
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ canvas-common/    # å·¥ä½œæµç¼–æ’æ ¸å¿ƒé€»è¾‘
â”‚   â”œâ”€â”€ skill-template/   # Skillå¼•æ“ (LangChainé›†æˆ)
â”‚   â”œâ”€â”€ agent-tools/      # å·¥å…·ç³»ç»ŸæŠ½è±¡å±‚
â”‚   â”œâ”€â”€ sandbox-agent/    # ä»£ç æ‰§è¡Œæ²™ç®±
â”‚   â”œâ”€â”€ common-types/     # è·¨åŒ…ç±»å‹å®šä¹‰
â”‚   â””â”€â”€ openapi-schema/   # API Schemaå®šä¹‰
```

**å…³é”®è®¾è®¡ç†å¿µ:**
- **å‰åç«¯å…±äº«æ ¸å¿ƒé€»è¾‘:** `canvas-common` åŒ…åŒæ—¶è¢«å‰ç«¯å’Œåç«¯ä¾èµ–ï¼Œç¡®ä¿å·¥ä½œæµç¼–æ’é€»è¾‘çš„ä¸€è‡´æ€§
- **å¾ªç¯ä¾èµ–é¿å…:** é€šè¿‡ `common-types` åŒ…å®šä¹‰æ¥å£ï¼Œæ‰“ç ´ `agent-tools` å’Œ `skill-template` ä¹‹é—´çš„å¾ªç¯ä¾èµ–

**1.2 å·¥ä½œæµæ‰§è¡Œçš„ä¸‰å±‚æ¶æ„**

```typescript
// å±‚çº§1: Canvaså±‚ - å‰ç«¯å¯è§†åŒ–ç¼–æ’
CanvasData {
  nodes: CanvasNode[]    // èŠ‚ç‚¹å®šä¹‰
  edges: CanvasEdge[]    // è¿æ¥å…³ç³»
  variables: WorkflowVariable[]  // å·¥ä½œæµå˜é‡
}

// å±‚çº§2: Workflowå±‚ - åç«¯è°ƒåº¦å¼•æ“
WorkflowExecution {
  executionId: string
  status: 'executing' | 'finish' | 'failed'
  nodeExecutions: WorkflowNodeExecution[]
}

// å±‚çº§3: Skillå±‚ - AIèƒ½åŠ›æ‰§è¡Œå•å…ƒ
SkillEngine {
  chatModel()           // LLMæ¨¡å‹å®ä¾‹åŒ–
  invoke(request)       // æŠ€èƒ½è°ƒç”¨
}
```

**æ ¸å¿ƒæºç ä½ç½®:**
- å‰ç«¯ç¼–æ’é€»è¾‘: `packages/canvas-common/src/workflow.ts`
- åç«¯è°ƒåº¦å¼•æ“: `apps/api/src/modules/workflow/workflow.service.ts`
- æŠ€èƒ½å¼•æ“: `packages/skill-template/src/base.ts`

---

### 2. æ™ºèƒ½ä½“ç¼–æ’æœºåˆ¶ï¼šå¦‚ä½•å®ç°å¯è§†åŒ–èŠ‚ç‚¹åˆ°Agentæ‰§è¡Œçš„æ˜ å°„ï¼Ÿ

#### 2.1 èŠ‚ç‚¹ç±»å‹ä½“ç³»

Refly å®šä¹‰äº†å¤šç§èŠ‚ç‚¹ç±»å‹ï¼Œæ¯ç§èŠ‚ç‚¹å¯¹åº”ä¸åŒçš„æ‰§è¡Œç­–ç•¥:

```typescript
type CanvasNodeType = 
  | 'skillResponse'     // AIæŠ€èƒ½èŠ‚ç‚¹ (æ ¸å¿ƒæ™ºèƒ½ä½“)
  | 'document'          // æ–‡æ¡£èŠ‚ç‚¹
  | 'codeArtifact'      // ä»£ç åˆ¶å“èŠ‚ç‚¹
  | 'resource'          // èµ„æºèŠ‚ç‚¹
  | 'image' | 'video' | 'audio'  // åª’ä½“èŠ‚ç‚¹
  | 'website'           // ç½‘ç«™èŠ‚ç‚¹
```

**å…³é”®å®ç° - èŠ‚ç‚¹æ‰§è¡Œå™¨:**

```typescript:1:163:packages/canvas-common/src/node-executor.ts
// ç®€åŒ–ç‰ˆèŠ‚ç‚¹æ‰§è¡Œå™¨
export class NodeExecutor {
  async executeNode(node: WorkflowNode): Promise<void> {
    switch (node.type) {
      case 'skill':
        await this.executeSkillNode(node);  // è°ƒç”¨LLM
        break;
      default:
        await this.executeGenericNode(node); // é€šç”¨å¤„ç†
    }
  }

  private async executeSkillNode(node: WorkflowNode): Promise<void> {
    // æ„å»ºæŠ€èƒ½è°ƒç”¨è¯·æ±‚
    const skillRequest: InvokeSkillRequest = {
      input: { query: node.title },
      context: this.buildSkillContext(node),
      skillName: 'commonQnA',
      resultId: node.entityId
    };
    // æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°
    for (let step = 1; step <= totalSteps; step++) {
      node.progress = (step / totalSteps) * 100;
      // ... å®é™…LLMè°ƒç”¨
    }
  }
}
```

#### 2.2 èŠ‚ç‚¹ç¼–æ’ç®—æ³• - æ‹“æ‰‘æ’åº

**æ ¸å¿ƒé—®é¢˜:** å¦‚ä½•ç¡®ä¿çˆ¶èŠ‚ç‚¹åœ¨å­èŠ‚ç‚¹ä¹‹å‰æ‰§è¡Œï¼Ÿ

**è§£å†³æ–¹æ¡ˆ:** ä½¿ç”¨æ‹“æ‰‘æ’åº (Topological Sort) ç»´æŠ¤æ‰§è¡Œé¡ºåº

```typescript:304:351:packages/canvas-common/src/workflow.ts
export const sortNodeExecutionsByExecutionOrder = <T extends WorkflowNodeExecution>(
  nodeExecutions: T[],
): T[] => {
  const nodeMap = new Map(nodeExecutions.map((n) => [n.nodeId, n]));
  const visited = new Set<string>();
  const result: T[] = [];

  const visit = (nodeExecution: T) => {
    if (visited.has(nodeExecution.nodeId)) return;
    visited.add(nodeExecution.nodeId);

    // å…ˆè®¿é—®æ‰€æœ‰çˆ¶èŠ‚ç‚¹
    const parentNodeIds = JSON.parse(nodeExecution.parentNodeIds || '[]') as string[];
    const parentNodes = parentNodeIds
      .map((parentId) => nodeMap.get(parentId))
      .filter((node): node is T => node !== undefined)
      .sort((a, b) => a.nodeId.localeCompare(b.nodeId));

    for (const parentNode of parentNodes) {
      visit(parentNode);
    }

    result.push(nodeExecution);
  };

  // æŒ‰åŸå§‹é¡ºåºè®¿é—®æ‰€æœ‰èŠ‚ç‚¹
  const sortedNodeExecutions = [...nodeExecutions].sort((a, b) => 
    a.nodeId.localeCompare(b.nodeId)
  );

  for (const nodeExecution of sortedNodeExecutions) {
    visit(nodeExecution);
  }

  return result;
};
```

**å…³é”®è®¾è®¡ç‚¹:**
1. **DFSéå†:** æ·±åº¦ä¼˜å…ˆæœç´¢ç¡®ä¿ä¾èµ–é“¾å®Œæ•´
2. **å»é‡æœºåˆ¶:** `visited` Set é¿å…é‡å¤è®¿é—®
3. **é¡ºåºä¿è¯:** åŒçº§èŠ‚ç‚¹æŒ‰ nodeId æ’åºï¼Œä¿æŒç¡®å®šæ€§

---

### 3. å¤šæ™ºèƒ½ä½“åä½œï¼šå¦‚ä½•å®ç°èŠ‚ç‚¹é—´çš„ä¸Šä¸‹æ–‡ä¼ é€’å’Œä¾èµ–ç®¡ç†ï¼Ÿ

#### 3.1 ä¸Šä¸‹æ–‡ä¼ é€’æœºåˆ¶

**æ ¸å¿ƒæ•°æ®ç»“æ„:**

```typescript:1:11:packages/canvas-common/src/context.ts
export const convertResultContextToItems = (
  context: SkillContext,
  history: ActionResult[],
): IContextItem[] => {
  const items: IContextItem[] = [];
  
  // å†å²ç»“æœè½¬æ¢
  for (const item of history ?? []) {
    items.push({
      type: 'skillResponse',
      entityId: item.resultId,
    });
  }
  
  // å†…å®¹åˆ—è¡¨è½¬æ¢
  for (const content of context?.contentList ?? []) {
    const metadata = content.metadata as any;
    items.push({
      type: metadata?.domain?.includes('resource') ? 'resource' : 'skillResponse',
      entityId: metadata?.entityId ?? '',
      title: metadata?.title ?? 'Selected Content',
      metadata: {
        contentPreview: content.content,
        selectedContent: content.content,
        // ...
      },
    });
  }
}
```

#### 3.2 ä¾èµ–å…³ç³»æ„å»º

**çˆ¶å­å…³ç³»æ˜ å°„:**

```typescript:97:128:packages/canvas-common/src/workflow.ts
const buildNodeRelationships = (nodes: CanvasNode[], edges: CanvasEdge[]) => {
  const nodeMap = new Map<string, CanvasNode>();
  const parentMap = new Map<string, string[]>();
  const childMap = new Map<string, string[]>();

  // åˆå§‹åŒ–æ˜ å°„
  for (const node of nodes) {
    nodeMap.set(node.id, node);
    parentMap.set(node.id, []);
    childMap.set(node.id, []);
  }

  // æ ¹æ®è¾¹æ„å»ºå…³ç³»
  for (const edge of edges || []) {
    const sourceId = edge.source;
    const targetId = edge.target;

    if (nodeMap.has(sourceId) && nodeMap.has(targetId)) {
      // å°†targetæ·»åŠ ä¸ºsourceçš„å­èŠ‚ç‚¹
      const sourceChildren = childMap.get(sourceId) || [];
      sourceChildren.push(targetId);
      childMap.set(sourceId, sourceChildren);

      // å°†sourceæ·»åŠ ä¸ºtargetçš„çˆ¶èŠ‚ç‚¹
      const targetParents = parentMap.get(targetId) || [];
      targetParents.push(sourceId);
      parentMap.set(targetId, targetParents);
    }
  }

  return { nodeMap, parentMap, childMap };
};
```

#### 3.3 ä¸Šä¸‹æ–‡å¢å¼º - å˜é‡è§£æ

**å·¥ä½œæµå˜é‡ä¸ä¸Šä¸‹æ–‡é¡¹çš„èåˆ:**

```typescript:46:77:packages/canvas-common/src/workflow.ts
export const updateContextItemsFromVariables = (
  contextItems: IContextItem[],
  variables: WorkflowVariable[],
): IContextItem[] => {
  const enhancedContextItems = [...contextItems];

  // éå†èµ„æºç±»å‹å˜é‡
  for (const variable of variables) {
    if (variable.variableType === 'resource') {
      for (const value of variable.value) {
        if (value.type === 'resource' && value.resource?.entityId) {
          // æ£€æŸ¥èµ„æºæ˜¯å¦å·²å­˜åœ¨äºä¸Šä¸‹æ–‡
          const existingItemIndex = enhancedContextItems.findIndex(
            (item) => item.entityId === value.resource?.entityId && item.type === 'resource',
          );

          if (existingItemIndex >= 0) {
            // æ›´æ–°å·²æœ‰ä¸Šä¸‹æ–‡é¡¹çš„æ ‡é¢˜ä¸ºå˜é‡å
            enhancedContextItems[existingItemIndex].title = value.resource.name;
          }
        }
      }
    }
  }

  return enhancedContextItems;
};
```

**å…³é”®æœºåˆ¶:**
1. **èµ„æºå˜é‡è§£æ:** å°†å·¥ä½œæµçº§åˆ«çš„èµ„æºå˜é‡æ³¨å…¥åˆ°èŠ‚ç‚¹ä¸Šä¸‹æ–‡
2. **å»é‡åˆå¹¶:** é¿å…åŒä¸€èµ„æºè¢«é‡å¤å¼•ç”¨
3. **æ ‡é¢˜è¦†ç›–:** ä½¿ç”¨å˜é‡åä½œä¸ºèµ„æºæ˜¾ç¤ºåç§°

---

### 4. å·¥ä½œæµæ‰§è¡Œå¼•æ“ï¼šå¦‚ä½•å®ç°åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦å’Œå¹¶å‘æ§åˆ¶ï¼Ÿ

#### 4.1 ä»»åŠ¡é˜Ÿåˆ—è®¾è®¡

Refly ä½¿ç”¨ **BullMQ** å®ç°åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦:

```typescript:33:66:apps/api/src/modules/workflow/workflow.service.ts
@Injectable()
export class WorkflowService {
  constructor(
    private readonly prisma: PrismaService,
    private readonly redis: RedisService,
    @InjectQueue(QUEUE_RUN_WORKFLOW) 
    private readonly runWorkflowQueue?: Queue<RunWorkflowJobData>,
    @InjectQueue(QUEUE_POLL_WORKFLOW)
    private readonly pollWorkflowQueue?: Queue<PollWorkflowJobData>,
  ) {}
}
```

**ä¸¤ä¸ªæ ¸å¿ƒé˜Ÿåˆ—:**

1. **RunWorkflowé˜Ÿåˆ—:** æ‰§è¡Œå•ä¸ªèŠ‚ç‚¹
2. **PollWorkflowé˜Ÿåˆ—:** è½®è¯¢å·¥ä½œæµçŠ¶æ€ï¼Œè§¦å‘ä¸‹ä¸€æ‰¹èŠ‚ç‚¹

#### 4.2 èŠ‚ç‚¹æ‰§è¡Œæµç¨‹

```typescript:399:521:apps/api/src/modules/workflow/workflow.service.ts
async runWorkflow(data: RunWorkflowJobData): Promise<void> {
  const { user, executionId, nodeId } = data;

  // 1. è·å–åˆ†å¸ƒå¼é” (é˜²æ­¢å¤šä¸ªWorkeré‡å¤æ‰§è¡Œ)
  const lockKey = `workflow:node:${executionId}:${nodeId}`;
  const releaseLock = await this.redis.acquireLock(lockKey);
  if (!releaseLock) {
    return;  // é”è·å–å¤±è´¥ï¼Œè·³è¿‡æ‰§è¡Œ
  }

  try {
    // 2. æŸ¥è¯¢èŠ‚ç‚¹æ‰§è¡Œè®°å½•
    const nodeExecution = await this.prisma.workflowNodeExecution.findFirst({
      where: { executionId, nodeId },
    });

    // 3. éªŒè¯çˆ¶èŠ‚ç‚¹æ˜¯å¦å…¨éƒ¨å®Œæˆ
    const parentNodeIds = safeParseJSON(nodeExecution.parentNodeIds) ?? [];
    const allParentsFinishedCount = await this.prisma.workflowNodeExecution.count({
      where: {
        executionId: nodeExecution.executionId,
        nodeId: { in: parentNodeIds as string[] },
        status: 'finish',
      },
    });
    const allParentsFinished = allParentsFinishedCount === (parentNodeIds?.length ?? 0);

    if (!allParentsFinished) {
      return;  // çˆ¶èŠ‚ç‚¹æœªå®Œæˆï¼Œè·³è¿‡
    }

    // 4. åŸå­æ€§çŠ¶æ€æ›´æ–° (é˜²æ­¢å¹¶å‘ç«äº‰)
    const updateRes = await this.prisma.workflowNodeExecution.updateMany({
      where: {
        nodeExecutionId: nodeExecution.nodeExecutionId,
        status: { in: ['init', 'waiting'] },
      },
      data: { status: 'executing', startTime: new Date(), progress: 0 },
    });

    if ((updateRes?.count ?? 0) === 0) {
      return;  // å…¶ä»–WorkeræŠ¢å…ˆæ‰§è¡Œäº†
    }

    // 5. æ‰§è¡ŒèŠ‚ç‚¹
    if (nodeExecution.nodeType === 'skillResponse') {
      await this.executeSkillResponseNode(user, nodeExecution);
    } else {
      await this.prisma.workflowNodeExecution.update({
        where: { nodeExecutionId: nodeExecution.nodeExecutionId },
        data: { status: 'finish', progress: 100, endTime: new Date() },
      });
    }
  } finally {
    await releaseLock?.();  // é‡Šæ”¾é”
  }
}
```

**å¹¶å‘æ§åˆ¶å…³é”®æŠ€æœ¯:**

1. **åˆ†å¸ƒå¼é”:** Rediså®ç°çš„é”æœºåˆ¶ï¼Œç¡®ä¿åŒä¸€èŠ‚ç‚¹ä¸è¢«å¤šæ¬¡æ‰§è¡Œ
2. **ä¹è§‚é”:** ä½¿ç”¨ `updateMany` + çŠ¶æ€æ¡ä»¶ï¼Œé˜²æ­¢çŠ¶æ€ç«äº‰
3. **å¹‚ç­‰æ€§è®¾è®¡:** é‡å¤æ‰§è¡ŒåŒä¸€ä»»åŠ¡ä¸ä¼šäº§ç”Ÿå‰¯ä½œç”¨

#### 4.3 è½®è¯¢è°ƒåº¦å™¨ (Pollæœºåˆ¶)

```typescript:526:835:apps/api/src/modules/workflow/workflow.service.ts
async pollWorkflow(data: PollWorkflowJobData): Promise<void> {
  const { user, executionId, nodeBehavior } = data;

  // 1. è·å–è½®è¯¢é”
  const lockKey = `workflow:poll:${executionId}`;
  const releaseLock = await this.redis.acquireLock(lockKey, POLL_LOCK_TTL_MS);
  if (!releaseLock) return;

  try {
    // 2. æ£€æŸ¥å·¥ä½œæµçŠ¶æ€å’Œè¶…æ—¶
    const workflowExecution = await this.prisma.workflowExecution.findUnique({
      where: { executionId },
    });

    if (workflowExecution.status === 'failed' || workflowExecution.status === 'finish') {
      return;  // å·²å®Œæˆï¼Œåœæ­¢è½®è¯¢
    }

    // 3. è¶…æ—¶å¤„ç†
    const executionAge = Date.now() - workflowExecution.createdAt.getTime();
    if (executionAge > WORKFLOW_EXECUTION_TIMEOUT_MS) {
      await this.prisma.workflowNodeExecution.updateMany({
        where: { executionId, status: { notIn: ['finish', 'failed'] } },
        data: { status: 'failed', errorMessage: 'Workflow timeout' },
      });
      await this.prisma.workflowExecution.update({
        where: { executionId },
        data: { status: 'failed' },
      });
      return;
    }

    // 4. åŠ è½½æ‰€æœ‰èŠ‚ç‚¹
    const allNodes = await this.prisma.workflowNodeExecution.findMany({
      where: { executionId },
    });

    // 5. æŸ¥æ‰¾å°±ç»ªçš„waitingèŠ‚ç‚¹
    const waitingSkillNodes = allNodes.filter(
      (n) => (n.status === 'init' || n.status === 'waiting') && n.nodeType === 'skillResponse',
    );

    for (const n of waitingSkillNodes) {
      const parents = (safeParseJSON(n.parentNodeIds) ?? []) as string[];
      const allParentsFinished = parents.every((p) => 
        statusByNodeId.get(p) === 'finish'
      );

      if (allParentsFinished && this.runWorkflowQueue) {
        // 6. å°†å°±ç»ªèŠ‚ç‚¹åŠ å…¥æ‰§è¡Œé˜Ÿåˆ—
        await this.runWorkflowQueue.add('runWorkflow', {
          user: { uid: user.uid },
          executionId,
          nodeId: n.nodeId,
          nodeBehavior,
        });
      }
    }

    // 7. è®¡ç®—æ‰§è¡Œç»Ÿè®¡
    const executedNodes = allNodes.filter(n => n.status === 'finish').length;
    const failedNodes = allNodes.filter(n => n.status === 'failed').length;
    const pendingNodes = allNodes.filter(n => 
      n.status === 'init' || n.status === 'waiting'
    ).length;
    const executingNodes = allNodes.filter(n => n.status === 'executing').length;

    // 8. æ›´æ–°å·¥ä½œæµçŠ¶æ€
    let newStatus = 'executing';
    if (failedNodes > 0) {
      newStatus = 'failed';
    } else if (pendingNodes === 0 && executingNodes === 0) {
      newStatus = 'finish';
    }

    await this.prisma.workflowExecution.update({
      where: { executionId },
      data: { executedNodes, failedNodes, status: newStatus },
    });

    // 9. å†³å®šæ˜¯å¦ç»§ç»­è½®è¯¢
    const hasPendingOrExecuting = pendingNodes > 0 || executingNodes > 0;
    if (hasPendingOrExecuting && newStatus === 'executing' && this.pollWorkflowQueue) {
      await this.pollWorkflowQueue.add(
        'pollWorkflow',
        { user, executionId, nodeBehavior },
        { delay: WORKFLOW_POLL_INTERVAL, removeOnComplete: true },
      );
    }
  } finally {
    await releaseLock?.();
  }
}
```

**è½®è¯¢æœºåˆ¶ä¼˜åŠ¿:**
- **è‡ªé€‚åº”è°ƒåº¦:** æ ¹æ®èŠ‚ç‚¹çŠ¶æ€åŠ¨æ€è§¦å‘ä¸‹ä¸€æ‰¹ä»»åŠ¡
- **æ•…éšœéš”ç¦»:** å•ä¸ªèŠ‚ç‚¹å¤±è´¥ä¸å½±å“æ•´ä½“å·¥ä½œæµ
- **è‡ªåŠ¨æ¢å¤:** è¶…æ—¶èŠ‚ç‚¹ä¼šè¢«æ ‡è®°ä¸ºå¤±è´¥ï¼Œä¸é˜»å¡åç»­æ‰§è¡Œ

---

### 5. ä¸Šä¸‹æ–‡ç®¡ç†ï¼šå¦‚ä½•å¤„ç†å¤§è§„æ¨¡ä¸Šä¸‹æ–‡å’Œè·¨èŠ‚ç‚¹çŠ¶æ€å…±äº«ï¼Ÿ

#### 5.1 ä¸Šä¸‹æ–‡è½¬æ¢ç®¡é“

Refly å®ç°äº†å¤šå±‚ä¸Šä¸‹æ–‡è½¬æ¢æœºåˆ¶:

```typescript:157:230:packages/canvas-common/src/context.ts
export const convertContextItemsToInvokeParams = (
  items: IContextItem[],
  resultIds: string[],
  workflowVariables?: WorkflowVariable[],
): SkillContext => {
  const purgedItems = purgeContextItems(items);

  // 1. æ„å»ºå˜é‡IDåˆ°æ–‡ä»¶IDçš„æ˜ å°„
  const variableToFileIdMap = new Map<string, {
    fileId: string;
    variableId: string;
    variableName: string;
  }>();

  // 2. æ”¶é›†èµ„æºå˜é‡ä¸­çš„æ–‡ä»¶
  const filesFromVariables: SkillContextFileItem[] = [];
  if (workflowVariables) {
    for (const variable of workflowVariables) {
      if (variable.variableType === 'resource' && variable.value?.length > 0) {
        const fileId = variable.value[0]?.resource?.fileId;
        if (fileId) {
          variableToFileIdMap.set(variable.variableId, {
            fileId,
            variableId: variable.variableId,
            variableName: variable.name,
          });
          filesFromVariables.push({
            fileId,
            variableId: variable.variableId,
            variableName: variable.name,
          });
        }
      }
    }
  }

  // 3. ä»ä¸Šä¸‹æ–‡é¡¹ä¸­è·å–æ–‡ä»¶
  const filesFromContextItems = purgedItems
    ?.filter((item) => item?.type === 'file')
    .map((item) => {
      // è§£æèµ„æºå˜é‡
      if (item.metadata?.source === 'variable' && item.metadata?.variableId) {
        const detail = variableToFileIdMap.get(item.metadata.variableId);
        if (detail) return detail;
      }
      // ç›´æ¥æ–‡ä»¶å¼•ç”¨
      return { fileId: item.entityId };
    })
    .filter((item): item is SkillContextFileItem => item !== null);

  // 4. åˆå¹¶æ–‡ä»¶ï¼Œå»é‡
  const allFiles = [...filesFromVariables, ...(filesFromContextItems ?? [])];

  const context: SkillContext = {
    files: deduplicate(allFiles, (item) => item.fileId),
    results: deduplicate(
      resultIds.map((resultId) => ({ resultId })),
      (item) => item.resultId,
    ),
  };

  return context;
};
```

**æ ¸å¿ƒè®¾è®¡ç‚¹:**
1. **å˜é‡è§£æ:** å·¥ä½œæµå˜é‡ â†’ æ–‡ä»¶IDæ˜ å°„
2. **å»é‡åˆå¹¶:** é¿å…é‡å¤å¼•ç”¨åŒä¸€èµ„æº
3. **ç±»å‹è½¬æ¢:** IContextItem â†’ SkillContext

#### 5.2 ä¸Šä¸‹æ–‡æ¸…ç†ä¸å­˜å‚¨ä¼˜åŒ–

```typescript:321:362:packages/canvas-common/src/context.ts
export const purgeContextForActionResult = (context: SkillContext) => {
  // ç§»é™¤å®é™…å†…å®¹ä»¥èŠ‚çœå­˜å‚¨ç©ºé—´
  const contextCopy: SkillContext = safeParseJSON(JSON.stringify(context ?? {}));
  
  if (contextCopy.resources) {
    for (const { resource } of contextCopy.resources) {
      if (resource) {
        resource.content = '';  // æ¸…ç©ºèµ„æºå†…å®¹
      }
    }
  }
  
  if (contextCopy.documents) {
    for (const { document } of contextCopy.documents) {
      if (document) {
        document.content = '';  // æ¸…ç©ºæ–‡æ¡£å†…å®¹
      }
    }
  }

  if (contextCopy.codeArtifacts) {
    for (const { codeArtifact } of contextCopy.codeArtifacts) {
      if (codeArtifact) {
        codeArtifact.content = '';  // æ¸…ç©ºä»£ç å†…å®¹
      }
    }
  }

  if (contextCopy.files) {
    for (const { file } of contextCopy.files) {
      if (file) {
        file.content = '';  // æ¸…ç©ºæ–‡ä»¶å†…å®¹
      }
    }
  }

  if (contextCopy.results) {
    for (const item of contextCopy.results) {
      item.result = undefined;  // æ¸…ç©ºç»“æœ
    }
  }

  return contextCopy;
};
```

**å­˜å‚¨ä¼˜åŒ–ç­–ç•¥:**
- **å†…å®¹åˆ†ç¦»:** åªä¿ç•™å…ƒæ•°æ®å’Œå¼•ç”¨ID
- **æ‡’åŠ è½½:** å®é™…å†…å®¹æŒ‰éœ€ä»æ•°æ®åº“åŠ è½½
- **å¤§å°æ§åˆ¶:** é˜²æ­¢ActionResultè¡¨è†¨èƒ€

---

### 6. Skillå¼•æ“è®¾è®¡ï¼šå¦‚ä½•æŠ½è±¡AIèƒ½åŠ›å¹¶å®ç°å¯æ‰©å±•çš„æŠ€èƒ½ç³»ç»Ÿï¼Ÿ

#### 6.1 Skillå¼•æ“æ¶æ„

Refly çš„ Skillç³»ç»ŸåŸºäº **LangChain** å’Œ **LangGraph** æ„å»º:

```typescript:1:200:packages/skill-template/src/base.ts
export abstract class BaseSkill {
  icon: Icon = { type: 'emoji', value: 'ğŸ”§' };
  placeholder = 'ğŸ”§';
  abstract name: string;
  abstract description: string;
  abstract configSchema: SkillTemplateConfigDefinition;
  abstract graphState: StateGraphArgs<BaseSkillState>['channels'];

  constructor(public engine: SkillEngine) {}

  // è½¬æ¢ä¸ºLangChain Runnable
  abstract toRunnable(): Runnable;

  // å‘å°„æŠ€èƒ½äº‹ä»¶
  emitEvent(data: Partial<SkillEvent>, config: SkillRunnableConfig) {
    const { emitter } = config?.configurable || {};
    if (!emitter) return;

    const eventData: SkillEvent = {
      event: data.event,
      resultId: config.configurable.resultId,
      step: config.metadata?.step,
      ...data,
    };

    // è‡ªåŠ¨æ¨æ–­äº‹ä»¶ç±»å‹
    if (!eventData.event) {
      if (eventData.log) eventData.event = 'log';
      else if (eventData.tokenUsage) eventData.event = 'token_usage';
      else if (eventData.structuredData) eventData.event = 'structured_data';
      else if (eventData.artifact) eventData.event = 'artifact';
      else if (eventData.toolCallResult) eventData.event = 'tool_call_stream';
    }

    emitter.emit(eventData.event, eventData);
  }

  // åˆ†å—å‘å°„å¤§æ•°æ® (é˜²æ­¢äº‹ä»¶ç³»ç»Ÿè¿‡è½½)
  async emitLargeDataEvent<T>(
    data: {
      event?: string;
      data: T[];
      buildEventData: (
        chunk: T[],
        meta: { isPartial: boolean; chunkIndex: number; totalChunks: number },
      ) => Partial<SkillEvent>;
    },
    config: SkillRunnableConfig,
    options: {
      maxChunkSize?: number;
      delayBetweenChunks?: number;
    } = {},
  ): Promise<void> {
    const { maxChunkSize = 500, delayBetweenChunks = 10 } = options;

    if (!data.data?.length || !config?.configurable?.emitter) {
      return;
    }

    // æŒ‰å¤§å°åˆ†å—
    const chunks: T[][] = [];
    let currentChunk: T[] = [];
    let currentSize = 0;

    for (const item of data.data) {
      const itemSize = JSON.stringify(item).length;

      if (currentSize + itemSize > maxChunkSize && currentChunk.length > 0) {
        chunks.push(currentChunk);
        currentChunk = [];
        currentSize = 0;
      }

      currentChunk.push(item);
      currentSize += itemSize;
    }

    if (currentChunk.length > 0) {
      chunks.push(currentChunk);
    }

    // å»¶è¿Ÿå‘å°„
    const emitPromises = chunks.map(
      (chunk, i) =>
        new Promise<void>((resolve) => {
          setTimeout(() => {
            const eventData = data.buildEventData(chunk, {
              isPartial: i < chunks.length - 1,
              chunkIndex: i,
              totalChunks: chunks.length,
            });
            this.emitEvent(eventData, config);
            resolve();
          }, i * delayBetweenChunks);
        }),
    );

    await Promise.all(emitPromises);
  }

  async _call(
    input: BaseSkillState,
    _runManager?: CallbackManagerForToolRun,
    config?: SkillRunnableConfig,
  ): Promise<string> {
    if (!config) {
      throw new Error('skill config is required');
    }

    // é…ç½®å¼•æ“
    this.engine.configure(config);

    // è®¾ç½®å½“å‰æŠ€èƒ½
    config.configurable.currentSkill ??= {
      name: this.name,
      icon: this.icon,
    };

    // é¢„å¤„ç†æŸ¥è¯¢å’Œä¸Šä¸‹æ–‡
    config.configurable.preprocessResult ??= await preprocess(
      input.query, 
      config, 
      this.engine
    );

    const response = await this.toRunnable().invoke(input, {
      ...config,
      metadata: {
        ...config.metadata,
        ...config.configurable.currentSkill,
        resultId: config.configurable.resultId,
      },
    });

    return response;
  }
}
```

#### 6.2 SkillEngine æ¥å£è®¾è®¡

ä¸ºäº†é¿å…å¾ªç¯ä¾èµ–ï¼ŒRefly åœ¨ `common-types` åŒ…ä¸­å®šä¹‰äº†æœ€å°æ¥å£:

```typescript:1:125:packages/common-types/src/skill-engine.ts
export interface ISkillEngine {
  /**
   * åˆ›å»ºèŠå¤©æ¨¡å‹å®ä¾‹
   * @param params - æ¨¡å‹å‚æ•° (temperature, topP, maxTokensç­‰)
   * @param scene - åœºæ™¯ç±»å‹ ('chat' | 'copilot' | 'agent' | 'titleGeneration')
   * @returns LangChain BaseChatModelå®ä¾‹
   */
  chatModel(params?: ChatModelParams, scene?: ModelScene): any;

  /** ReflyæœåŠ¡å®ä¾‹ (æ–‡ä»¶æ“ä½œç­‰) */
  service?: any;

  /** æ—¥å¿—å®ä¾‹ */
  logger?: ILogger;

  /** é…ç½®å¼•æ“è¿è¡Œæ—¶é…ç½® */
  configure?(config: any): void;

  /** è·å–é…ç½®å€¼ */
  getConfig?(key?: string): any;
}

export interface ChatModelParams {
  temperature?: number;
  topP?: number;
  maxTokens?: number;
  [key: string]: any;
}

export type ModelScene = 
  | 'chat'              // å¯¹è¯åœºæ™¯
  | 'copilot'           // Copilotè¾…åŠ©
  | 'agent'             // Agentè‡ªä¸»å†³ç­–
  | 'titleGeneration'   // æ ‡é¢˜ç”Ÿæˆ
  | 'queryAnalysis';    // æŸ¥è¯¢åˆ†æ

export interface ILogger {
  log(message: any, ...optionalParams: any[]): void;
  error(message: any, ...optionalParams: any[]): void;
  warn(message: any, ...optionalParams: any[]): void;
  debug(message: any, ...optionalParams: any[]): void;
}
```

**è®¾è®¡äº®ç‚¹:**
1. **æœ€å°æ¥å£:** åªæš´éœ²å¿…è¦çš„æ–¹æ³•ï¼Œé™ä½è€¦åˆ
2. **ç±»å‹å®‰å…¨:** ä½¿ç”¨ TypeScript æ³›å‹ç¡®ä¿ç±»å‹æ­£ç¡®
3. **åœºæ™¯åŒºåˆ†:** ä¸åŒåœºæ™¯ä½¿ç”¨ä¸åŒçš„æ¨¡å‹é…ç½®

#### 6.3 ReflyService - æœåŠ¡é›†æˆå±‚

```typescript:91:283:apps/api/src/modules/skill/skill-engine.service.ts
buildReflyService = (): ReflyService => {
  return {
    getUserMediaConfig: async (user, mediaType) => {
      return await this.providerService.getUserMediaConfig(user, mediaType);
    },
    generateMedia: async (user, req) => {
      return await this.mediaGeneratorService.generate(user, req);
    },
    getActionResult: async (user, req) => {
      return await this.actionService.getActionResult(user, req);
    },
    createCanvas: async (user, req) => {
      const canvas = await this.canvasService.createCanvas(user, req);
      const canvasDTO = canvasPO2DTO(canvas);
      if (canvasDTO.usedToolsets && canvasDTO.usedToolsets.length > 0) {
        canvasDTO.usedToolsets = await this.toolService.populateToolsetsWithDefinition(
          canvasDTO.usedToolsets,
        );
      }
      return buildSuccessResponse(canvasDTO);
    },
    webSearch: async (user, req) => {
      return await this.searchService.webSearch(user, req);
    },
    rerank: async (user, query, results, options) => {
      return await this.ragService.rerank(user, query, results, options);
    },
    librarySearch: async (user, req, options) => {
      return await this.searchService.search(user, req, options);
    },
    crawlUrl: async (user, url) => {
      try {
        const parserFactory = new ParserFactory(this.config, this.providerService);
        const jinaParser = await parserFactory.createWebParser(user, {
          resourceId: `temp-${Date.now()}`,
        });
        const result = await jinaParser.parse(url);
        return {
          title: result.title,
          content: result.content,
          metadata: { ...result.metadata, url },
        };
      } catch (error) {
        this.logger.error(`Failed to crawl URL ${url}: ${error.stack}`);
        return { title: '', content: '', metadata: { url, error: error.message } };
      }
    },
    uploadFile: async (user, param) => {
      return await this.miscService.uploadFile(user, param);
    },
    readFile: async (user, fileId) => {
      return await this.driveService.getDriveFileDetail(user, fileId);
    },
    writeFile: async (user, param) => {
      return await this.driveService.createDriveFile(user, param);
    },
    execute: async (user, req) => {
      return await this.scaleboxService.execute(user, req);
    },
    // ... æ›´å¤šæœåŠ¡æ–¹æ³•
  };
};
```

**æœåŠ¡å±‚èŒè´£:**
- **ç»Ÿä¸€å…¥å£:** ä¸ºSkillæä¾›ç»Ÿä¸€çš„ä¸šåŠ¡èƒ½åŠ›è®¿é—®æ¥å£
- **ä¾èµ–æ³¨å…¥:** é€šè¿‡NestJSçš„ModuleRefåŠ¨æ€è·å–æœåŠ¡å®ä¾‹
- **é”™è¯¯å¤„ç†:** é›†ä¸­å¤„ç†å¼‚å¸¸å¹¶è¿”å›æ ‡å‡†å“åº”

---

### 7. å·¥å…·ç³»ç»Ÿè®¾è®¡ï¼šå¦‚ä½•å®ç°å¯æ’æ‹”çš„Toolç”Ÿæ€ï¼Ÿ

#### 7.1 å·¥å…·æŠ½è±¡å±‚

Refly åŸºäº LangChain çš„ `StructuredTool` å®ç°äº†ä¸‰å±‚å·¥å…·æŠ½è±¡:

```typescript:1:218:packages/agent-tools/src/base.ts
/**
 * å·¥å…·è°ƒç”¨ç»“æœ
 */
export interface ToolCallResult {
  status: 'success' | 'error';
  data?: any;
  error?: string;
  summary?: string;
  creditCost?: number;  // ä¿¡ç”¨æˆæœ¬
  files?: DriveFile[];
}

/**
 * å·¥å…·ç±»å‹
 */
export type ToolType =
  | 'builtin'          // å†…ç½®å·¥å…·
  | 'regular'          // å¸¸è§„å·¥å…·
  | 'dynamic'          // åŠ¨æ€å·¥å…·
  | 'composio'         // Composioé›†æˆ
  | 'mcp'              // MCPåè®®å·¥å…·
  | 'config_based'     // é…ç½®é©±åŠ¨å·¥å…·
  | 'external_api'     // å¤–éƒ¨API
  | 'external_oauth';  // OAuthè®¤è¯å¤–éƒ¨API

/**
 * å·¥å…·åŸºç±»
 */
export abstract class AgentBaseTool<TParams = unknown> extends StructuredTool {
  /** å·¥å…·é›†key */
  abstract toolsetKey: string;

  /** å·¥å…·ç±»å‹ */
  toolType: ToolType = 'regular';

  constructor(_params?: TParams) {
    super();
  }
}

/**
 * å·¥å…·é›†åŸºç±»
 */
export abstract class AgentBaseToolset<TParams = unknown> {
  /** å·¥å…·é›†key */
  abstract toolsetKey: string;

  /** å·¥å…·æ„é€ å™¨æ•°ç»„ */
  abstract tools: readonly AgentToolConstructor<TParams>[];

  /** å·¥å…·é›†å‚æ•° */
  protected params?: TParams;

  /** å»¶è¿Ÿåˆ›å»ºçš„å·¥å…·å®ä¾‹ */
  protected toolInstances: AgentBaseTool<TParams>[] = [];

  constructor(params?: TParams) {
    this.params = params;
  }

  /**
   * åˆå§‹åŒ–å·¥å…·å®ä¾‹
   */
  initializeTools(params?: TParams): AgentBaseTool<TParams>[] {
    const effectiveParams = (params ?? this.params) as TParams | undefined;

    if (effectiveParams === undefined && (this.tools?.length ?? 0) > 0) {
      // å°è¯•æ— å‚æ„é€ 
      this.toolInstances = this.tools
        ?.map((Ctor) => {
          try {
            const NoArgCtor = Ctor as new () => AgentBaseTool<TParams>;
            return new NoArgCtor();
          } catch {
            return undefined;
          }
        })
        ?.filter((tool): tool is AgentBaseTool<TParams> => tool != null) ?? [];
      return this.toolInstances;
    }

    // å¸¦å‚æ„é€ 
    this.toolInstances = (this.tools ?? [])
      .map((Ctor) => {
        const WithArgCtor = Ctor as new (p: TParams) => AgentBaseTool<TParams>;
        return new WithArgCtor(effectiveParams as TParams);
      })
      .filter((tool): tool is AgentBaseTool<TParams> => tool != null);

    return this.toolInstances;
  }

  /**
   * æ ¹æ®åç§°è·å–å·¥å…·å®ä¾‹
   */
  getToolInstance(name: string): AgentBaseTool<TParams> {
    if (!this.toolInstances?.length) {
      this.initializeTools();
    }

    const toolInstance = this.toolInstances?.find((tool) => tool?.name === name);
    if (!toolInstance) {
      throw new Error(`Tool instance ${name} not found`);
    }
    return toolInstance;
  }

  /**
   * æŸ¥æ‰¾å·¥å…·æ„é€ å™¨ (ä¸å®ä¾‹åŒ–)
   */
  getToolConstructor(name: string): AgentToolConstructor<TParams> {
    const tools = this.tools ?? ([] as unknown as readonly AgentToolConstructor<TParams>[]);
    const ctor = tools.find((Ctor) => {
      try {
        const NoArgCtor = Ctor as new () => AgentBaseTool<TParams>;
        const tmp = new NoArgCtor();
        return tmp?.name === name;
      } catch {
        return (
          ((Ctor as unknown as { prototype?: { name?: string } })?.prototype?.name ?? '') === name
        );
      }
    });

    if (!ctor) {
      throw new Error(`Tool ${name} not found in toolset ${this.toolsetKey}`);
    }

    return ctor as AgentToolConstructor<TParams>;
  }
}

/**
 * åŸºç¡€å·¥å…·å‚æ•°
 */
export interface BaseToolParams {
  reflyService?: ReflyService;
  isGlobalToolset?: boolean;
  engine?: ISkillEngine;  // SkillEngineå®ä¾‹ (ç”¨äºLLMè°ƒç”¨)
}
```

**å…³é”®è®¾è®¡ç‚¹:**

1. **æ³›å‹å‚æ•°åŒ–:** `TParams` æ”¯æŒä¸åŒå·¥å…·çš„è‡ªå®šä¹‰å‚æ•°
2. **å»¶è¿Ÿå®ä¾‹åŒ–:** å·¥å…·å®ä¾‹æŒ‰éœ€åˆ›å»ºï¼ŒèŠ‚çœèµ„æº
3. **æ„é€ å™¨çµæ´»æ€§:** æ”¯æŒæœ‰å‚/æ— å‚æ„é€ ï¼Œå…¼å®¹ä¸åŒåœºæ™¯

#### 7.2 æ²™ç®±Agentå·¥å…·ç¤ºä¾‹

```typescript:1:154:packages/sandbox-agent/src/chains.ts
/**
 * ä½¿ç”¨LLMæ£€æŸ¥ä»£ç æ˜¯å¦ä¿®æ”¹æ–‡ä»¶
 */
export async function getFileModifications(
  code: string,
  llm: BaseChatModel,
): Promise<string[] | null> {
  // 1. å¿«é€Ÿå¯å‘å¼æ£€æŸ¥
  const fileOperationPatterns = [
    /\.to_csv\(/,
    /\.to_excel\(/,
    /\.to_json\(/,
    /\.savefig\(/,
    /with open\(/,
    /open\(['"](.*?)['"]/,
    /\.write\(/,
    /\.dump\(/,
  ];

  const hasFileOperations = fileOperationPatterns.some((pattern) => pattern.test(code));

  if (!hasFileOperations) {
    return null;
  }

  try {
    // 2. ä½¿ç”¨LLMè¿›è¡Œæ·±åº¦åˆ†æ
    const chain = DETERMINE_MODIFICATIONS_PROMPT.pipe(llm);
    const response = await chain.invoke({ code });

    if (typeof response.content === 'string') {
      const modifications = parseModifications(response.content);
      return modifications;
    }
  } catch (error) {
    console.error('Error determining modifications with LLM:', error);
  }

  // 3. å›é€€ï¼šæ­£åˆ™æå–æ–‡ä»¶å
  const filenameMatches = [
    ...code.matchAll(/['"]([\w\-\.]+\.(?:csv|xlsx|json|png|jpg|jpeg|pdf|txt|html))['"]/gi),
  ];

  if (filenameMatches.length === 0) {
    return null;
  }

  const filenames = filenameMatches.map((match) => match[1]);
  return [...new Set(filenames)]; // å»é‡
}

/**
 * ä½¿ç”¨LLMç§»é™¤ä¸‹è½½é“¾æ¥
 */
export async function removeDownloadLink(text: string, llm: BaseChatModel): Promise<string> {
  try {
    const chain = REMOVE_DL_LINK_PROMPT.pipe(llm);
    const response = await chain.invoke({ input_response: text });

    if (typeof response.content === 'string') {
      return response.content;
    }
  } catch (error) {
    console.error('Error removing download link with LLM:', error);
  }

  // å›é€€ï¼šåŸºäºæ­£åˆ™çš„æ¸…ç†
  return extractCleanResponse(text);
}

/**
 * åˆ†æä»£ç æ½œåœ¨é—®é¢˜
 */
export async function analyzeCode(
  code: string,
  llm: BaseChatModel,
): Promise<{ hasIssues: boolean; issues: string[] }> {
  const prompt = ChatPromptTemplate.fromMessages([
    [
      'system',
      'You are a code analysis assistant. Analyze the given Python code for potential issues, errors, or improvements.',
    ],
    ['human', 'Analyze this Python code and list any potential issues:\n\n```python\n{code}\n```'],
  ]);

  try {
    const chain = prompt.pipe(llm);
    const response = await chain.invoke({ code });

    if (typeof response.content === 'string') {
      const content = response.content.toLowerCase();
      const hasIssues =
        content.includes('issue') || content.includes('error') || content.includes('problem');

      return {
        hasIssues,
        issues: hasIssues ? [response.content] : [],
      };
    }
  } catch (error) {
    console.error('Error analyzing code:', error);
  }

  return { hasIssues: false, issues: [] };
}

/**
 * ç”Ÿæˆä»£ç å»ºè®®
 */
export async function generateCodeSuggestion(
  userRequest: string,
  llm: BaseChatModel,
): Promise<string> {
  const prompt = ChatPromptTemplate.fromMessages([
    [
      'system',
      'You are a helpful Python coding assistant. Generate Python code to fulfill user requests.',
    ],
    ['human', 'Generate Python code for the following request:\n\n{request}'],
  ]);

  const chain = prompt.pipe(llm);
  const response = await chain.invoke({ request: userRequest });

  if (typeof response.content === 'string') {
    return extractPythonCode(response.content);
  }

  return '';
}
```

**å·¥å…·è®¾è®¡æ¨¡å¼:**
1. **å¯å‘å¼+LLMæ··åˆ:** å…ˆå¿«é€Ÿæ£€æŸ¥ï¼Œå†ç²¾ç¡®åˆ†æ
2. **å›é€€æœºåˆ¶:** LLMå¤±è´¥æ—¶ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
3. **å®‰å…¨éš”ç¦»:** ä»£ç æ‰§è¡Œåœ¨æ²™ç®±ç¯å¢ƒ (Scalebox)

---

### 8. çŠ¶æ€åŒæ­¥æœºåˆ¶ï¼šå‰ç«¯Canvasä¸åç«¯æ•°æ®åº“å¦‚ä½•å®æ—¶åŒæ­¥ï¼Ÿ

#### 8.1 å¢é‡åŒæ­¥åè®®

Refly ä½¿ç”¨ **äº‹åŠ¡å¼å·®åˆ†åŒæ­¥** (Transaction-based Diff Sync):

```typescript
// æ ¸å¿ƒæ•°æ®ç»“æ„
interface SyncTransaction {
  txId: string;
  createdAt: number;
  syncedAt: number;
  source: { type: 'user' | 'system' };
  nodeDiffs: NodeDiff[];    // èŠ‚ç‚¹å˜æ›´
  edgeDiffs: EdgeDiff[];    // è¾¹å˜æ›´
}

type NodeDiff = 
  | { type: 'add'; node: CanvasNode }
  | { type: 'update'; id: string; from?: Partial<CanvasNode>; to: Partial<CanvasNode> }
  | { type: 'delete'; id: string; node?: CanvasNode };
```

**åŒæ­¥æµç¨‹:**

```typescript:268:282:apps/api/src/modules/workflow/workflow.service.ts
private async syncNodeDiffToCanvas(user: User, canvasId: string, nodeDiffs: NodeDiff[]) {
  await this.canvasSyncService.syncState(user, {
    canvasId,
    transactions: [
      {
        txId: genTransactionId(),
        createdAt: Date.now(),
        syncedAt: Date.now(),
        source: { type: 'system' },
        nodeDiffs,
        edgeDiffs: [],
      },
    ],
  });
}
```

**ä¼˜åŠ¿:**
1. **å¢é‡æ›´æ–°:** åªä¼ è¾“å˜æ›´éƒ¨åˆ†ï¼Œå‡å°‘ç½‘ç»œå¼€é”€
2. **å†²çªè§£å†³:** é€šè¿‡ txId å’Œæ—¶é—´æˆ³æ£€æµ‹å¹¶è§£å†³å†²çª
3. **äº‹åŠ¡æ€§:** ä¿è¯å¤šä¸ªå˜æ›´çš„åŸå­æ€§

#### 8.2 å®æ—¶é€šçŸ¥ (WebSocket/SSE)

å·¥ä½œæµæ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œé€šè¿‡äº‹ä»¶æµå‘å‰ç«¯æ¨é€è¿›åº¦:

```typescript:67:96:packages/skill-template/src/base.ts
emitEvent(data: Partial<SkillEvent>, config: SkillRunnableConfig) {
  const { emitter } = config?.configurable || {};

  if (!emitter) {
    return;
  }

  const eventData: SkillEvent = {
    event: data.event,
    resultId: config.configurable.resultId,
    step: config.metadata?.step,
    ...data,
  };

  // è‡ªåŠ¨æ¨æ–­äº‹ä»¶ç±»å‹
  if (!eventData.event) {
    if (eventData.log) {
      eventData.event = 'log';
    } else if (eventData.tokenUsage) {
      eventData.event = 'token_usage';
    } else if (eventData.structuredData) {
      eventData.event = 'structured_data';
    } else if (eventData.artifact) {
      eventData.event = 'artifact';
    } else if (eventData.toolCallResult) {
      eventData.event = 'tool_call_stream';
    }
  }

  emitter.emit(eventData.event, eventData);
}
```

**äº‹ä»¶ç±»å‹:**
- `log`: æ‰§è¡Œæ—¥å¿—
- `token_usage`: Tokenæ¶ˆè€—ç»Ÿè®¡
- `artifact`: ç”Ÿæˆçš„åˆ¶å“ (ä»£ç ã€å›¾ç‰‡ç­‰)
- `tool_call_stream`: å·¥å…·è°ƒç”¨è¿›åº¦

---

### 9. é”™è¯¯å¤„ç†ä¸å®¹é”™ï¼šå¦‚ä½•ä¿è¯å·¥ä½œæµçš„å¥å£®æ€§ï¼Ÿ

#### 9.1 è¶…æ—¶ä¸é‡è¯•æœºåˆ¶

```typescript:43:46:apps/api/src/modules/workflow/workflow.service.ts
const WORKFLOW_POLL_INTERVAL = 1500;
const WORKFLOW_EXECUTION_TIMEOUT_MS = 30 * 60 * 1000; // 30 minutes
const NODE_EXECUTION_TIMEOUT_MS = 10 * 60 * 1000; // 10 minutes
const POLL_LOCK_TTL_MS = 5000; // 5 seconds
```

**è¶…æ—¶å¤„ç†é€»è¾‘:**

```typescript:564:591:apps/api/src/modules/workflow/workflow.service.ts
// æ£€æŸ¥å·¥ä½œæµè¶…æ—¶
const executionAge = Date.now() - workflowExecution.createdAt.getTime();
if (executionAge > WORKFLOW_EXECUTION_TIMEOUT_MS) {
  this.logger.warn(
    `[pollWorkflow] Workflow ${executionId} timed out after ${executionAge}ms (limit: ${WORKFLOW_EXECUTION_TIMEOUT_MS}ms)`,
  );

  // æ ‡è®°æ‰€æœ‰æœªå®ŒæˆèŠ‚ç‚¹ä¸ºå¤±è´¥
  await this.prisma.workflowNodeExecution.updateMany({
    where: {
      executionId,
      status: { notIn: ['finish', 'failed'] },
    },
    data: {
      status: 'failed',
      errorMessage: `Workflow execution timeout exceeded (${Math.floor(executionAge / 1000)}s)`,
      endTime: new Date(),
    },
  });

  // æ ‡è®°å·¥ä½œæµä¸ºå¤±è´¥å¹¶åœæ­¢è½®è¯¢
  await this.prisma.workflowExecution.update({
    where: { executionId },
    data: { status: 'failed' },
  });

  this.logger.error(`[pollWorkflow] Workflow ${executionId} marked as failed due to timeout`);
  return;
}
```

**èŠ‚ç‚¹çº§è¶…æ—¶:**

```typescript:612:632:apps/api/src/modules/workflow/workflow.service.ts
// æ£€æŸ¥å¡ä½çš„æ‰§è¡ŒèŠ‚ç‚¹å¹¶è¶…æ—¶
const now = new Date();
const stuckExecutingNodes = allNodes.filter((n) => {
  if (n.status !== 'executing' || !n.startTime) return false;
  const nodeAge = now.getTime() - n.startTime.getTime();
  return nodeAge > NODE_EXECUTION_TIMEOUT_MS;
});

if (stuckExecutingNodes.length > 0) {
  const timedOutNodeIds = stuckExecutingNodes.map((n) => n.nodeExecutionId);
  await this.prisma.workflowNodeExecution.updateMany({
    where: { nodeExecutionId: { in: timedOutNodeIds } },
    data: {
      status: 'failed',
      errorMessage: `Node execution timeout exceeded (${Math.floor(NODE_EXECUTION_TIMEOUT_MS / 1000)}s)`,
      endTime: now,
    },
  });
  this.logger.warn(
    `[pollWorkflow] Marked ${stuckExecutingNodes.length} nodes as failed due to timeout in execution ${executionId}`,
  );
}
```

#### 9.2 å¤±è´¥ä¼ æ’­æ§åˆ¶

Refly é‡‡ç”¨ **å±€éƒ¨å¤±è´¥ä¸é˜»å¡å…¨å±€** çš„ç­–ç•¥:

```typescript:745:780:apps/api/src/modules/workflow/workflow.service.ts
// è®¡ç®—èŠ‚ç‚¹ç»Ÿè®¡
const executedNodes = allNodes.filter(n => n.status === 'finish').length;
const failedNodes = allNodes.filter(n => n.status === 'failed').length;
const pendingNodes = allNodes.filter(n => 
  n.status === 'init' || n.status === 'waiting'
).length;
const executingNodes = allNodes.filter(n => n.status === 'executing').length;

// ç¡®å®šå·¥ä½œæµçŠ¶æ€
let newStatus: 'executing' | 'failed' | 'finish' = 'executing';
if (failedNodes > 0) {
  newStatus = 'failed';  // ä»»ä¸€èŠ‚ç‚¹å¤±è´¥åˆ™å·¥ä½œæµå¤±è´¥
} else if (pendingNodes === 0 && executingNodes === 0) {
  newStatus = 'finish';  // æ‰€æœ‰èŠ‚ç‚¹å®Œæˆ
}
```

**å¤±è´¥ç­–ç•¥:**
1. **å¿«é€Ÿå¤±è´¥:** ä¸€æ—¦æœ‰èŠ‚ç‚¹å¤±è´¥ï¼Œç«‹å³æ ‡è®°å·¥ä½œæµå¤±è´¥
2. **çŠ¶æ€éš”ç¦»:** å¤±è´¥èŠ‚ç‚¹ä¸å½±å“å·²å®ŒæˆèŠ‚ç‚¹çš„ç»“æœ
3. **æ—¥å¿—ä¿ç•™:** æ‰€æœ‰é”™è¯¯ä¿¡æ¯ä¿å­˜åˆ° `errorMessage` å­—æ®µ

---

### 10. å¯æ‰©å±•æ€§è®¾è®¡ï¼šå¦‚ä½•æ”¯æŒè‡ªå®šä¹‰Skillå’Œç¬¬ä¸‰æ–¹é›†æˆï¼Ÿ

#### 10.1 Skillæ¨¡æ¿ç³»ç»Ÿ

Refly é€šè¿‡æŠ½è±¡åŸºç±» `BaseSkill` å®ç°Skillæ‰©å±•:

```typescript
// å¼€å‘è€…åªéœ€å®ç°è¿™äº›æ–¹æ³•
export abstract class BaseSkill {
  abstract name: string;
  abstract description: string;
  abstract configSchema: SkillTemplateConfigDefinition;
  abstract graphState: StateGraphArgs<BaseSkillState>['channels'];
  abstract toRunnable(): Runnable;
}
```

**ç¤ºä¾‹: è‡ªå®šä¹‰QnA Skill**

```typescript
export class CustomQnASkill extends BaseSkill {
  name = 'customQnA';
  description = 'è‡ªå®šä¹‰é—®ç­”æŠ€èƒ½';
  
  configSchema = {
    // é…ç½®é¡¹å®šä¹‰
    promptTemplate: { type: 'string', required: false },
    temperature: { type: 'number', default: 0.7 },
  };

  graphState = {
    query: { value: (x, y) => y ?? x },
    context: { value: (x, y) => y ?? x },
    answer: { value: (x, y) => y ?? x },
  };

  toRunnable(): Runnable {
    const llm = this.engine.chatModel({ temperature: 0.7 });
    
    return RunnableSequence.from([
      // 1. é¢„å¤„ç†è¾“å…¥
      RunnableLambda.from((input) => ({
        ...input,
        processedQuery: this.preprocessQuery(input.query),
      })),
      
      // 2. è°ƒç”¨LLM
      ChatPromptTemplate.fromTemplate('{processedQuery}').pipe(llm),
      
      // 3. åå¤„ç†è¾“å‡º
      RunnableLambda.from((output) => this.postprocessOutput(output)),
    ]);
  }
}
```

#### 10.2 ç¬¬ä¸‰æ–¹å·¥å…·é›†æˆ

**æ”¯æŒçš„é›†æˆç±»å‹:**

```typescript:9:18:packages/agent-tools/src/base.ts
export type ToolType =
  | 'builtin'          // å†…ç½®å·¥å…·
  | 'regular'          // å¸¸è§„å·¥å…·
  | 'dynamic'          // åŠ¨æ€å·¥å…·
  | 'composio'         // Composioå¹³å°é›†æˆ
  | 'mcp'              // Model Context Protocol
  | 'config_based'     // é…ç½®é©±åŠ¨å·¥å…·
  | 'external_api'     // å¤–éƒ¨APIç›´æ¥è°ƒç”¨
  | 'external_oauth';  // OAuthè®¤è¯çš„å¤–éƒ¨API
```

**é›†æˆæµç¨‹:**

1. **å®šä¹‰å·¥å…·ç±»:**
```typescript
export class MyCustomTool extends AgentBaseTool<MyToolParams> {
  toolsetKey = 'my-custom-toolset';
  name = 'my_tool';
  description = 'æˆ‘çš„è‡ªå®šä¹‰å·¥å…·';

  async _call(input: any): Promise<ToolCallResult> {
    try {
      const result = await this.callExternalAPI(input);
      return {
        status: 'success',
        data: result,
        summary: 'æ‰§è¡ŒæˆåŠŸ',
      };
    } catch (error) {
      return {
        status: 'error',
        error: error.message,
      };
    }
  }
}
```

2. **æ³¨å†Œå·¥å…·é›†:**
```typescript
export class MyCustomToolset extends AgentBaseToolset<MyToolParams> {
  toolsetKey = 'my-custom-toolset';
  tools = [MyCustomTool] as const;
}
```

3. **å‰ç«¯é…ç½®:**
```yaml
toolsets:
  - key: my-custom-toolset
    name: æˆ‘çš„å·¥å…·é›†
    icon: { type: 'emoji', value: 'ğŸ› ï¸' }
    tools:
      - name: my_tool
        displayName: æˆ‘çš„å·¥å…·
        parameters:
          apiKey: ${env.MY_API_KEY}
```

---

## æ€»ç»“ä¸å¯å‘

### æ ¸å¿ƒä¼˜åŠ¿

1. **å‰åç«¯ä¸€è‡´æ€§:** é€šè¿‡ Monorepo å’Œå…±äº«åŒ…ç¡®ä¿é€»è¾‘ä¸€è‡´
2. **å¯è§†åŒ–ç¼–æ’:** Canvas + @xyflow/react æä¾›ç›´è§‚çš„å·¥ä½œæµè®¾è®¡ä½“éªŒ
3. **åˆ†å¸ƒå¼è°ƒåº¦:** BullMQ + Redis å®ç°é«˜å¯ç”¨çš„ä»»åŠ¡è°ƒåº¦
4. **AIèƒ½åŠ›æŠ½è±¡:** SkillEngine ç»Ÿä¸€ç®¡ç† LLM è°ƒç”¨å’Œ Token è®¡è´¹
5. **å·¥å…·ç”Ÿæ€å¼€æ”¾:** åŸºäº LangChain çš„å·¥å…·ç³»ç»Ÿæ˜“äºæ‰©å±•

### å¯å€Ÿé‰´çš„è®¾è®¡æ¨¡å¼

1. **äº‹åŠ¡å¼å·®åˆ†åŒæ­¥:** é«˜æ•ˆçš„å‰åç«¯çŠ¶æ€åŒæ­¥æ–¹æ¡ˆ
2. **æ‹“æ‰‘æ’åºè°ƒåº¦:** ä¼˜é›…çš„DAGæ‰§è¡Œé¡ºåºç®¡ç†
3. **è½®è¯¢+é˜Ÿåˆ—æ··åˆæ¶æ„:** å¹³è¡¡å®æ—¶æ€§ä¸èµ„æºæ¶ˆè€—
4. **åˆ†å±‚ä¸Šä¸‹æ–‡ç®¡ç†:** å·¥ä½œæµå˜é‡ â†’ èŠ‚ç‚¹ä¸Šä¸‹æ–‡ â†’ Skillè¾“å…¥
5. **æœ€å°æ¥å£è®¾è®¡:** é€šè¿‡ `common-types` æ‰“ç ´å¾ªç¯ä¾èµ–

### æ½œåœ¨æ”¹è¿›æ–¹å‘

1. **DAGå¯è§†åŒ–å¢å¼º:** æ”¯æŒæ›´å¤æ‚çš„æ¡ä»¶åˆ†æ”¯å’Œå¾ªç¯ç»“æ„
2. **è°ƒè¯•èƒ½åŠ›:** å¢åŠ æ–­ç‚¹ã€å•æ­¥æ‰§è¡Œã€å˜é‡æŸ¥çœ‹ç­‰åŠŸèƒ½
3. **ç‰ˆæœ¬æ§åˆ¶:** å·¥ä½œæµç‰ˆæœ¬ç®¡ç†å’Œå›æ»šæœºåˆ¶
4. **æ€§èƒ½ä¼˜åŒ–:** å¤§è§„æ¨¡å·¥ä½œæµçš„å¹¶å‘æ‰§è¡Œä¼˜åŒ–
5. **ç›‘æ§å‘Šè­¦:** å®æ—¶ç›‘æ§å·¥ä½œæµå¥åº·çŠ¶æ€å’Œèµ„æºæ¶ˆè€—

---

## å‚è€ƒèµ„æ–™

- **æºç ä»“åº“:** https://github.com/refly-ai/refly
- **å®˜æ–¹æ–‡æ¡£:** https://docs.refly.ai/
- **æŠ€æœ¯æ ˆ:**
  - LangChain: https://js.langchain.com/
  - LangGraph: https://langchain-ai.github.io/langgraphjs/
  - NestJS: https://nestjs.com/
  - @xyflow/react: https://reactflow.dev/
  - BullMQ: https://docs.bullmq.io/

---

**ç”Ÿæˆæ—¶é—´:** 2024-12-22  
**åˆ†æç‰ˆæœ¬:** Refly v1.0.0  
**æ–‡æ¡£ä½œè€…:** AgenticX Research Team

---

## æ ¸å¿ƒå·¥ç¨‹åŒ–è¿½é—®ï¼šAgenticX çš„è½åœ°è·¯å¾„

åŸºäºå¯¹ Refly.AI çš„æ·±åº¦åˆ†æï¼Œç»“åˆ AgenticX é¡¹ç›®çš„å®é™…éœ€æ±‚ï¼Œä»¥ä¸‹5ä¸ªæ ¸å¿ƒè¿½é—®å°†æŒ‡å¯¼æˆ‘ä»¬çš„æŠ€æœ¯é€‰å‹å’Œæ¶æ„è®¾è®¡ï¼š

### è¿½é—®1ï¼šå·¥ä½œæµè°ƒåº¦å¼•æ“ - è½®è¯¢ vs äº‹ä»¶é©±åŠ¨ï¼Œå¦‚ä½•é€‰æ‹©ï¼Ÿ

**Refly çš„æ–¹æ¡ˆï¼š**
- ä½¿ç”¨ **è½®è¯¢æœºåˆ¶** (Poll Workflow)ï¼Œæ¯1.5ç§’æ£€æŸ¥ä¸€æ¬¡å·¥ä½œæµçŠ¶æ€
- ä¼˜ç‚¹ï¼šå®ç°ç®€å•ï¼Œå®¹é”™æ€§å¥½ï¼Œæ˜“äºè°ƒè¯•
- ç¼ºç‚¹ï¼šå­˜åœ¨å»¶è¿Ÿï¼ˆæœ€é«˜1.5ç§’ï¼‰ï¼Œé«˜å¹¶å‘ä¸‹ Redis å‹åŠ›å¤§ï¼Œèµ„æºåˆ©ç”¨ç‡ä¸å¤Ÿé«˜

**AgenticX çš„æ€è€ƒæ–¹å‘ï¼š**

```typescript
// æ–¹æ¡ˆA: çº¯äº‹ä»¶é©±åŠ¨ (ä¼˜åŒ–å»¶è¿Ÿ)
class EventDrivenWorkflowScheduler {
  // èŠ‚ç‚¹å®Œæˆæ—¶ç«‹å³è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹
  async onNodeComplete(nodeId: string, executionId: string) {
    const childNodes = await this.getReadyChildNodes(nodeId);
    await Promise.all(
      childNodes.map(child => this.runWorkflowQueue.add(child))
    );
  }
  
  // ä¼˜ç‚¹: é›¶å»¶è¿Ÿï¼Œå®æ—¶æ€§å¼º
  // ç¼ºç‚¹: éœ€è¦å®Œå–„çš„äº‹ä»¶æ€»çº¿ï¼Œæ•…éšœæ¢å¤å¤æ‚
}

// æ–¹æ¡ˆB: æ··åˆæ¨¡å¼ (å¹³è¡¡æ€§èƒ½ä¸å¯é æ€§)
class HybridWorkflowScheduler {
  // æ­£å¸¸æµç¨‹: äº‹ä»¶é©±åŠ¨
  async onNodeComplete(nodeId: string) {
    await this.triggerChildNodesImmediately(nodeId);
  }
  
  // å…œåº•æœºåˆ¶: å®šæœŸè½®è¯¢æ£€æŸ¥é—æ¼
  @Cron('*/10 * * * * *')  // æ¯10ç§’è½®è¯¢ä¸€æ¬¡
  async pollStuckWorkflows() {
    const stuckExecutions = await this.findStuckExecutions();
    // æ¢å¤å¡ä½çš„å·¥ä½œæµ
  }
}
```

**å…³é”®å†³ç­–ç‚¹ï¼š**
1. **å®æ—¶æ€§è¦æ±‚å¤šé«˜ï¼Ÿ** é‡‘èåœºæ™¯éœ€è¦<100ms å“åº”ï¼Œå¯è§†åŒ–å·¥å…·å¯ä»¥å®¹å¿1-2ç§’å»¶è¿Ÿ
2. **å¹¶å‘è§„æ¨¡å¤šå¤§ï¼Ÿ** å•æœº100å¹¶å‘ç”¨è½®è¯¢å³å¯ï¼Œ10000+å¹¶å‘å¿…é¡»äº‹ä»¶é©±åŠ¨
3. **å®¹é”™éœ€æ±‚å¦‚ä½•ï¼Ÿ** å…³é”®ä¸šåŠ¡æµç¨‹éœ€è¦è½®è¯¢å…œåº•ï¼Œç¡®ä¿ä¸é—æ¼ä»»åŠ¡

**AgenticX å»ºè®®ï¼š**
- **åˆæœŸ**ï¼šä½¿ç”¨è½®è¯¢ï¼ˆ0.5-1ç§’é—´éš”ï¼‰ï¼Œå¿«é€ŸéªŒè¯ä¸šåŠ¡é€»è¾‘
- **ä¼˜åŒ–æœŸ**ï¼šå¼•å…¥äº‹ä»¶é©±åŠ¨ï¼Œä¿ç•™è½®è¯¢ä½œä¸ºå…œåº•æœºåˆ¶
- **æˆç†ŸæœŸ**ï¼šåŸºäº Kafka/Pulsar çš„å®Œå…¨äº‹ä»¶é©±åŠ¨æ¶æ„

---

### è¿½é—®2ï¼šè¶…å¤§ä¸Šä¸‹æ–‡ç®¡ç† - å¦‚ä½•çªç ´ç™¾ä¸‡ Token é™åˆ¶ï¼Ÿ

**Refly çš„æ–¹æ¡ˆï¼š**
- ä¸Šä¸‹æ–‡æ¸…ç†ï¼šåªä¿ç•™å…ƒæ•°æ®å’Œå¼•ç”¨ ID
- æ‡’åŠ è½½ï¼šå†…å®¹æŒ‰éœ€ä»æ•°æ®åº“åŠ è½½
- å±€é™æ€§ï¼šå•ä¸ªèŠ‚ç‚¹ä¸Šä¸‹æ–‡ä»å— LLM Token é™åˆ¶ï¼ˆé€šå¸¸ 32k-200kï¼‰

**AgenticX çš„çªç ´æ–¹å‘ï¼š**

```python
# æ–¹æ¡ˆA: åˆ†å±‚ä¸Šä¸‹æ–‡å‹ç¼© (Hierarchical Context Compression)
class LayeredContextManager:
    def __init__(self):
        self.l1_cache = {}  # çƒ­æ•°æ®ï¼šæœ€è¿‘è®¿é—®çš„å®Œæ•´ä¸Šä¸‹æ–‡
        self.l2_cache = {}  # æ¸©æ•°æ®ï¼šå‹ç¼©åçš„æ‘˜è¦
        self.l3_storage = {}  # å†·æ•°æ®ï¼šä»…ä¿ç•™å¼•ç”¨
    
    async def get_context_for_node(self, node_id: str, max_tokens: int) -> Context:
        """æ™ºèƒ½ä¸Šä¸‹æ–‡ç»„è£…"""
        # 1. è·å–ç›´æ¥çˆ¶èŠ‚ç‚¹çš„å®Œæ•´è¾“å‡ºï¼ˆL1ç¼“å­˜ï¼‰
        parent_outputs = await self.get_from_l1(node_id)
        
        # 2. è·å–é—´æ¥ä¾èµ–èŠ‚ç‚¹çš„æ‘˜è¦ï¼ˆL2ç¼“å­˜ï¼‰
        ancestor_summaries = await self.get_from_l2(node_id)
        
        # 3. æ ¹æ® Token é¢„ç®—åŠ¨æ€è£å‰ª
        context = self.assemble_context(
            parent_outputs, 
            ancestor_summaries,
            max_tokens=max_tokens * 0.7  # é¢„ç•™30%ç»™æ–°ç”Ÿæˆ
        )
        
        return context

# æ–¹æ¡ˆB: åŠ¨æ€ä¸Šä¸‹æ–‡æ£€ç´¢ (RAG-based Context Retrieval)
class RAGContextManager:
    async def retrieve_relevant_context(
        self, 
        query: str, 
        execution_id: str,
        max_tokens: int
    ) -> Context:
        """åŸºäºæŸ¥è¯¢çš„ä¸Šä¸‹æ–‡æ£€ç´¢"""
        # 1. å°†æ‰€æœ‰å†å²èŠ‚ç‚¹è¾“å‡ºå‘é‡åŒ–å­˜å‚¨
        all_history = await self.vector_store.query(
            collection=f"execution_{execution_id}",
            query_embedding=self.embed(query),
            top_k=50
        )
        
        # 2. ä½¿ç”¨ Rerank æ¨¡å‹ç²¾æ’
        reranked = await self.rerank_model.rank(
            query=query,
            documents=all_history,
            top_k=10
        )
        
        # 3. åŠ¨æ€å¡«å……åˆ° Token é¢„ç®—
        context = self.fill_to_budget(reranked, max_tokens)
        
        return context
```

**å·¥ç¨‹åŒ–æŒ‘æˆ˜ï¼š**

| æŒ‘æˆ˜ | Refly æ–¹æ¡ˆ | AgenticX æ”¹è¿› |
|------|-----------|--------------|
| ä¸Šä¸‹æ–‡è†¨èƒ€ | æ‰‹åŠ¨æ¸…ç† | è‡ªåŠ¨å‹ç¼© + TTLè¿‡æœŸç­–ç•¥ |
| å…³é”®ä¿¡æ¯ä¸¢å¤± | ä¾èµ–å¼€å‘è€…æ ‡æ³¨ | åŸºäºé‡è¦æ€§è¯„åˆ†çš„æ™ºèƒ½ä¿ç•™ |
| è·¨èŠ‚ç‚¹å¼•ç”¨ | ç®€å•IDå¼•ç”¨ | è¯­ä¹‰åŒ–å¼•ç”¨ + è‡ªåŠ¨è§£å¼•ç”¨ |
| Token è®¡è´¹ | å…¨é‡è®¡è´¹ | å¢é‡è®¡è´¹ï¼ˆåªè®¡ç®—æ–°å¢éƒ¨åˆ†ï¼‰ |

**AgenticX å®æ–½è·¯çº¿ï¼š**
1. **Phase 1**ï¼šå®ç° Refly çš„æ¸…ç†æœºåˆ¶ï¼ˆä¿ç•™å…ƒæ•°æ®ï¼‰
2. **Phase 2**ï¼šå¼•å…¥ä¸Šä¸‹æ–‡æ‘˜è¦ï¼ˆä½¿ç”¨å°æ¨¡å‹ç”Ÿæˆ Summaryï¼‰
3. **Phase 3**ï¼šæ„å»ºå‘é‡åŒ–å­˜å‚¨ + RAG æ£€ç´¢
4. **Phase 4**ï¼šå®ç°è‡ªé€‚åº”ä¸Šä¸‹æ–‡ç»„è£…ï¼ˆæ ¹æ®ä»»åŠ¡ç±»å‹åŠ¨æ€è°ƒæ•´ç­–ç•¥ï¼‰

---

### è¿½é—®3ï¼šå·¥å…·ç³»ç»Ÿæ ‡å‡†åŒ– - å¦‚ä½•å…¼å®¹ MCP/LangChain/OpenAI Function Callingï¼Ÿ

**Refly çš„æ–¹æ¡ˆï¼š**
- åŸºäº LangChain çš„ `StructuredTool`
- æ”¯æŒå¤šç§å·¥å…·ç±»å‹ï¼ˆbuiltin, mcp, composioç­‰ï¼‰
- å±€é™æ€§ï¼šä¸åŒå·¥å…·åè®®é—´çš„è½¬æ¢æˆæœ¬é«˜ï¼Œå·¥å…·å‘ç°æœºåˆ¶ä¸å¤Ÿæ™ºèƒ½

**AgenticX çš„ç»Ÿä¸€æŠ½è±¡å±‚ï¼š**

```python
# æ ¸å¿ƒæŠ½è±¡ï¼šå·¥å…·åè®®é€‚é…å™¨
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional
from pydantic import BaseModel

class ToolParameter(BaseModel):
    """ç»Ÿä¸€çš„å·¥å…·å‚æ•°å®šä¹‰"""
    name: str
    type: str  # string, number, boolean, object, array
    description: str
    required: bool = False
    enum: Optional[List[Any]] = None
    default: Optional[Any] = None

class ToolDefinition(BaseModel):
    """ç»Ÿä¸€çš„å·¥å…·å®šä¹‰"""
    name: str
    description: str
    parameters: List[ToolParameter]
    returns: Dict[str, Any]
    
    # æ‰©å±•å…ƒæ•°æ®
    category: str  # search, data_processing, code_execution...
    cost_per_call: Optional[float] = None  # è®¡è´¹ä¿¡æ¯
    rate_limit: Optional[int] = None  # é™æµé…ç½®
    timeout_ms: int = 30000  # è¶…æ—¶æ—¶é—´

class ToolAdapter(ABC):
    """å·¥å…·åè®®é€‚é…å™¨åŸºç±»"""
    
    @abstractmethod
    async def discover_tools(self) -> List[ToolDefinition]:
        """å‘ç°å¯ç”¨å·¥å…·"""
        pass
    
    @abstractmethod
    async def invoke_tool(
        self, 
        tool_name: str, 
        parameters: Dict[str, Any]
    ) -> Any:
        """è°ƒç”¨å·¥å…·"""
        pass

# é€‚é…å™¨å®ç°ç¤ºä¾‹
class MCPAdapter(ToolAdapter):
    """MCP åè®®é€‚é…å™¨"""
    
    async def discover_tools(self) -> List[ToolDefinition]:
        # ä» MCP Server è·å–å·¥å…·åˆ—è¡¨
        mcp_tools = await self.mcp_client.list_tools()
        
        # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
        return [
            ToolDefinition(
                name=tool.name,
                description=tool.description,
                parameters=self._convert_mcp_schema(tool.inputSchema),
                returns={"type": "object"},
                category=self._infer_category(tool)
            )
            for tool in mcp_tools
        ]
    
    async def invoke_tool(self, tool_name: str, parameters: Dict) -> Any:
        result = await self.mcp_client.call_tool(tool_name, parameters)
        return result.content

class LangChainAdapter(ToolAdapter):
    """LangChain å·¥å…·é€‚é…å™¨"""
    
    def __init__(self, langchain_tools: List[BaseTool]):
        self.tools = langchain_tools
    
    async def discover_tools(self) -> List[ToolDefinition]:
        return [
            ToolDefinition(
                name=tool.name,
                description=tool.description,
                parameters=self._convert_langchain_schema(tool.args_schema),
                returns={"type": "any"},
                category="general"
            )
            for tool in self.tools
        ]

class OpenAIFunctionAdapter(ToolAdapter):
    """OpenAI Function Calling é€‚é…å™¨"""
    
    async def discover_tools(self) -> List[ToolDefinition]:
        # OpenAI functions å·²ç»æ˜¯æ ‡å‡†æ ¼å¼
        return [
            ToolDefinition(**func_def)
            for func_def in self.function_definitions
        ]

# ç»Ÿä¸€å·¥å…·æ³¨å†Œä¸­å¿ƒ
class ToolRegistry:
    def __init__(self):
        self.adapters: List[ToolAdapter] = []
        self.tool_cache: Dict[str, ToolDefinition] = {}
    
    def register_adapter(self, adapter: ToolAdapter):
        """æ³¨å†Œå·¥å…·é€‚é…å™¨"""
        self.adapters.append(adapter)
    
    async def discover_all_tools(self) -> List[ToolDefinition]:
        """å‘ç°æ‰€æœ‰å¯ç”¨å·¥å…·"""
        all_tools = []
        for adapter in self.adapters:
            tools = await adapter.discover_tools()
            all_tools.extend(tools)
        
        # å»é‡ + ç¼“å­˜
        unique_tools = self._deduplicate_tools(all_tools)
        self.tool_cache = {tool.name: tool for tool in unique_tools}
        
        return unique_tools
    
    async def invoke(self, tool_name: str, parameters: Dict) -> Any:
        """æ™ºèƒ½è·¯ç”±å·¥å…·è°ƒç”¨"""
        if tool_name not in self.tool_cache:
            raise ToolNotFoundError(f"Tool {tool_name} not found")
        
        # æ‰¾åˆ°å¯¹åº”çš„é€‚é…å™¨å¹¶è°ƒç”¨
        for adapter in self.adapters:
            if await adapter.has_tool(tool_name):
                return await adapter.invoke_tool(tool_name, parameters)
```

**å·¥å…·å‘ç°ä¸æ¨èæœºåˆ¶ï¼š**

```python
class IntelligentToolSelector:
    """æ™ºèƒ½å·¥å…·é€‰æ‹©å™¨"""
    
    def __init__(self, registry: ToolRegistry):
        self.registry = registry
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
    
    async def select_tools_for_task(
        self, 
        task_description: str,
        max_tools: int = 5
    ) -> List[ToolDefinition]:
        """åŸºäºä»»åŠ¡æè¿°æ™ºèƒ½é€‰æ‹©å·¥å…·"""
        # 1. è·å–æ‰€æœ‰å·¥å…·
        all_tools = await self.registry.discover_all_tools()
        
        # 2. è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
        task_embedding = self.embedding_model.encode(task_description)
        tool_embeddings = self.embedding_model.encode(
            [f"{tool.name}: {tool.description}" for tool in all_tools]
        )
        
        # 3. ç›¸ä¼¼åº¦æ’åº
        similarities = cosine_similarity([task_embedding], tool_embeddings)[0]
        top_indices = similarities.argsort()[-max_tools:][::-1]
        
        # 4. è¿”å›æ¨èå·¥å…·
        return [all_tools[i] for i in top_indices if similarities[i] > 0.3]
```

**AgenticX ä¼˜åŠ¿ï¼š**
1. **åè®®æ— å…³**ï¼šé€šè¿‡é€‚é…å™¨æ¨¡å¼æ”¯æŒä»»æ„å·¥å…·åè®®
2. **æ™ºèƒ½å‘ç°**ï¼šåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„å·¥å…·æ¨è
3. **ç»Ÿä¸€è®¡è´¹**ï¼šåœ¨æŠ½è±¡å±‚ç»Ÿä¸€å¤„ç†æˆæœ¬å’Œé™æµ
4. **å¯è§‚æµ‹æ€§**ï¼šæ‰€æœ‰å·¥å…·è°ƒç”¨éƒ½ç»è¿‡ç»Ÿä¸€ç›‘æ§ç‚¹

---

### è¿½é—®4ï¼šåˆ†å¸ƒå¼å®¹é”™ - å·¥ä½œæµå¦‚ä½•ä»æ•…éšœä¸­æ¢å¤ï¼Ÿ

**Refly çš„æ–¹æ¡ˆï¼š**
- è¶…æ—¶æ£€æµ‹ + å¤±è´¥æ ‡è®°
- åˆ†å¸ƒå¼é”é˜²æ­¢é‡å¤æ‰§è¡Œ
- å±€é™æ€§ï¼šèŠ‚ç‚¹å¤±è´¥åæ— æ³•è‡ªåŠ¨é‡è¯•ï¼Œç¼ºå°‘æ£€æŸ¥ç‚¹æœºåˆ¶

**AgenticX çš„å¢å¼ºå®¹é”™è®¾è®¡ï¼š**

```python
from enum import Enum
from dataclasses import dataclass
from typing import Optional

class NodeFailurePolicy(Enum):
    """èŠ‚ç‚¹å¤±è´¥ç­–ç•¥"""
    FAIL_FAST = "fail_fast"          # ç«‹å³å¤±è´¥ï¼Œåœæ­¢å·¥ä½œæµ
    RETRY = "retry"                   # è‡ªåŠ¨é‡è¯•
    SKIP = "skip"                     # è·³è¿‡èŠ‚ç‚¹ï¼Œç»§ç»­æ‰§è¡Œ
    FALLBACK = "fallback"             # ä½¿ç”¨å¤‡ç”¨èŠ‚ç‚¹
    MANUAL_INTERVENTION = "manual"    # äººå·¥ä»‹å…¥

@dataclass
class CheckpointData:
    """æ£€æŸ¥ç‚¹æ•°æ®"""
    execution_id: str
    node_id: str
    state: Dict[str, Any]  # èŠ‚ç‚¹çŠ¶æ€å¿«ç…§
    timestamp: int
    retry_count: int

class FaultTolerantWorkflowEngine:
    def __init__(self):
        self.checkpoint_store = CheckpointStore()  # æ£€æŸ¥ç‚¹å­˜å‚¨
        self.dead_letter_queue = DeadLetterQueue()  # æ­»ä¿¡é˜Ÿåˆ—
    
    async def execute_node_with_recovery(
        self, 
        node: WorkflowNode,
        execution_context: ExecutionContext
    ) -> NodeResult:
        """å¸¦æ¢å¤èƒ½åŠ›çš„èŠ‚ç‚¹æ‰§è¡Œ"""
        
        # 1. æ£€æŸ¥æ˜¯å¦æœ‰æ£€æŸ¥ç‚¹ï¼ˆä»æ•…éšœæ¢å¤ï¼‰
        checkpoint = await self.checkpoint_store.get(
            execution_id=execution_context.execution_id,
            node_id=node.id
        )
        
        if checkpoint:
            # ä»æ£€æŸ¥ç‚¹æ¢å¤
            execution_context.restore_from_checkpoint(checkpoint)
        
        # 2. æ‰§è¡ŒèŠ‚ç‚¹ï¼ˆå¸¦é‡è¯•é€»è¾‘ï¼‰
        max_retries = node.failure_policy.get('max_retries', 3)
        retry_count = checkpoint.retry_count if checkpoint else 0
        
        for attempt in range(retry_count, max_retries + 1):
            try:
                # åˆ›å»ºæ£€æŸ¥ç‚¹
                await self.checkpoint_store.save(CheckpointData(
                    execution_id=execution_context.execution_id,
                    node_id=node.id,
                    state=execution_context.to_dict(),
                    timestamp=time.time(),
                    retry_count=attempt
                ))
                
                # æ‰§è¡ŒèŠ‚ç‚¹
                result = await self.execute_node(node, execution_context)
                
                # æˆåŠŸï¼Œåˆ é™¤æ£€æŸ¥ç‚¹
                await self.checkpoint_store.delete(
                    execution_context.execution_id, 
                    node.id
                )
                
                return result
                
            except RecoverableError as e:
                # å¯æ¢å¤é”™è¯¯ï¼Œæ‰§è¡Œé‡è¯•é€»è¾‘
                if attempt < max_retries:
                    # æŒ‡æ•°é€€é¿
                    await asyncio.sleep(2 ** attempt)
                    continue
                else:
                    # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                    return await self.handle_final_failure(
                        node, 
                        execution_context, 
                        e
                    )
            
            except UnrecoverableError as e:
                # ä¸å¯æ¢å¤é”™è¯¯ï¼Œç›´æ¥å¤±è´¥
                return await self.handle_final_failure(
                    node, 
                    execution_context, 
                    e
                )
    
    async def handle_final_failure(
        self, 
        node: WorkflowNode,
        context: ExecutionContext,
        error: Exception
    ) -> NodeResult:
        """å¤„ç†æœ€ç»ˆå¤±è´¥"""
        
        policy = node.failure_policy.get('on_final_failure', NodeFailurePolicy.FAIL_FAST)
        
        if policy == NodeFailurePolicy.FAIL_FAST:
            # å¿«é€Ÿå¤±è´¥ï¼Œåœæ­¢æ•´ä¸ªå·¥ä½œæµ
            await self.abort_workflow(context.execution_id)
            raise WorkflowFailedError(f"Node {node.id} failed: {error}")
        
        elif policy == NodeFailurePolicy.SKIP:
            # è·³è¿‡èŠ‚ç‚¹ï¼Œæ ‡è®°ä¸ºå¤±è´¥ä½†ç»§ç»­æ‰§è¡Œ
            return NodeResult(
                status='skipped',
                output=None,
                error=str(error)
            )
        
        elif policy == NodeFailurePolicy.FALLBACK:
            # æ‰§è¡Œå¤‡ç”¨èŠ‚ç‚¹
            fallback_node_id = node.failure_policy.get('fallback_node_id')
            fallback_node = await self.get_node(fallback_node_id)
            return await self.execute_node(fallback_node, context)
        
        elif policy == NodeFailurePolicy.MANUAL_INTERVENTION:
            # å‘é€é€šçŸ¥ï¼Œç­‰å¾…äººå·¥ä»‹å…¥
            await self.dead_letter_queue.add({
                'execution_id': context.execution_id,
                'node_id': node.id,
                'error': str(error),
                'context': context.to_dict()
            })
            return NodeResult(status='pending_manual_review')

# å·¥ä½œæµçº§åˆ«çš„å®¹é”™
class WorkflowRecoveryManager:
    """å·¥ä½œæµæ¢å¤ç®¡ç†å™¨"""
    
    async def recover_stuck_workflows(self):
        """æ¢å¤å¡ä½çš„å·¥ä½œæµï¼ˆå®šæ—¶ä»»åŠ¡ï¼‰"""
        # 1. æŸ¥æ‰¾è¶…æ—¶çš„æ‰§è¡Œ
        stuck_executions = await self.find_stuck_executions()
        
        for execution in stuck_executions:
            # 2. åŠ è½½æœ€æ–°æ£€æŸ¥ç‚¹
            checkpoints = await self.checkpoint_store.get_all(execution.id)
            
            # 3. é‡å»ºæ‰§è¡ŒçŠ¶æ€
            recovered_state = self.rebuild_state_from_checkpoints(checkpoints)
            
            # 4. ä»å¤±è´¥ç‚¹ç»§ç»­æ‰§è¡Œ
            await self.resume_workflow(execution.id, recovered_state)
    
    async def resume_workflow(
        self, 
        execution_id: str, 
        state: ExecutionState
    ):
        """æ¢å¤å·¥ä½œæµæ‰§è¡Œ"""
        # æ‰¾åˆ°æ‰€æœ‰æœªå®Œæˆçš„èŠ‚ç‚¹
        pending_nodes = state.get_pending_nodes()
        
        # é‡æ–°è°ƒåº¦
        for node in pending_nodes:
            if await self.check_dependencies_satisfied(node, state):
                await self.runWorkflowQueue.add({
                    'execution_id': execution_id,
                    'node_id': node.id,
                    'recovered': True
                })
```

**å®¹é”™èƒ½åŠ›å¯¹æ¯”ï¼š**

| ç‰¹æ€§ | Refly | AgenticX å¢å¼º |
|------|-------|--------------|
| èŠ‚ç‚¹é‡è¯• | âŒ ä¸æ”¯æŒ | âœ… å¯é…ç½®é‡è¯•ç­–ç•¥ |
| æ£€æŸ¥ç‚¹æ¢å¤ | âŒ ä¸æ”¯æŒ | âœ… è‡ªåŠ¨æ£€æŸ¥ç‚¹ + æ¢å¤ |
| å¤±è´¥ç­–ç•¥ | å•ä¸€ï¼ˆå¿«é€Ÿå¤±è´¥ï¼‰ | å¤šç­–ç•¥ï¼ˆé‡è¯•/è·³è¿‡/å›é€€/äººå·¥ï¼‰ |
| çŠ¶æ€æŒä¹…åŒ– | éƒ¨åˆ†ï¼ˆä»…æ•°æ®åº“ï¼‰ | å®Œæ•´ï¼ˆæ£€æŸ¥ç‚¹ + çŠ¶æ€å¿«ç…§ï¼‰ |
| æ•…éšœç›‘æ§ | åŸºç¡€æ—¥å¿— | æ­»ä¿¡é˜Ÿåˆ— + å‘Šè­¦ |

**å·¥ç¨‹åŒ–å»ºè®®ï¼š**
1. **åˆæœŸ**ï¼šå®ç°åŸºç¡€é‡è¯•æœºåˆ¶ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
2. **ä¸­æœŸ**ï¼šå¼•å…¥æ£€æŸ¥ç‚¹ç³»ç»Ÿï¼Œæ”¯æŒä»æ•…éšœç‚¹æ¢å¤
3. **æˆç†ŸæœŸ**ï¼šæ„å»ºå®Œæ•´çš„æ­»ä¿¡é˜Ÿåˆ— + äººå·¥ä»‹å…¥æµç¨‹

---

### è¿½é—®5ï¼šå¤šç”¨æˆ·åä½œå†²çª - å¦‚ä½•å¤„ç†å¹¶å‘ç¼–è¾‘ï¼Ÿ

**Refly çš„æ–¹æ¡ˆï¼š**
- äº‹åŠ¡å¼å·®åˆ†åŒæ­¥ï¼ˆTransaction-based Diff Syncï¼‰
- åŸºäºæ—¶é—´æˆ³çš„ç®€å•å†²çªæ£€æµ‹
- å±€é™æ€§ï¼šä¸æ”¯æŒå¤šç”¨æˆ·å®æ—¶åä½œï¼Œå†²çªè§£å†³ç­–ç•¥å•ä¸€ï¼ˆåå†™è¦†ç›–ï¼‰

**AgenticX çš„åä½œå¢å¼ºï¼š**

```python
from typing import List, Dict, Any
from enum import Enum

class ConflictResolutionStrategy(Enum):
    """å†²çªè§£å†³ç­–ç•¥"""
    LAST_WRITE_WINS = "last_write_wins"      # æœ€åå†™å…¥è·èƒœ
    FIRST_WRITE_WINS = "first_write_wins"    # ç¬¬ä¸€æ¬¡å†™å…¥è·èƒœ
    MERGE = "merge"                           # æ™ºèƒ½åˆå¹¶
    MANUAL = "manual"                         # äººå·¥è§£å†³

class OperationType(Enum):
    """æ“ä½œç±»å‹ï¼ˆç”¨äº OT ç®—æ³•ï¼‰"""
    INSERT = "insert"
    DELETE = "delete"
    UPDATE = "update"
    MOVE = "move"

@dataclass
class Operation:
    """åä½œæ“ä½œ"""
    type: OperationType
    path: str  # JSONPath è·¯å¾„
    value: Any
    position: Optional[int] = None
    timestamp: int
    user_id: str
    version: int  # å‘é‡æ—¶é’Ÿ

class CRDTCanvas:
    """åŸºäº CRDT çš„ Canvas åä½œå¼•æ“"""
    
    def __init__(self):
        # ä½¿ç”¨ Automerge CRDT åº“
        from automerge import Automerge
        self.doc = Automerge.init()
        self.operations_log: List[Operation] = []
    
    async def apply_operation(
        self, 
        operation: Operation,
        local_version: int
    ) -> CanvasData:
        """åº”ç”¨æ“ä½œï¼ˆè‡ªåŠ¨å¤„ç†å†²çªï¼‰"""
        
        # CRDT è‡ªåŠ¨åˆå¹¶ï¼Œæ— éœ€å†²çªæ£€æµ‹
        if operation.type == OperationType.INSERT:
            self.doc = Automerge.change(
                self.doc,
                lambda doc: doc['nodes'].insert(
                    operation.position,
                    operation.value
                )
            )
        
        elif operation.type == OperationType.UPDATE:
            self.doc = Automerge.change(
                self.doc,
                lambda doc: self._set_by_path(
                    doc, 
                    operation.path, 
                    operation.value
                )
            )
        
        # è®°å½•æ“ä½œæ—¥å¿—
        self.operations_log.append(operation)
        
        return self._to_canvas_data(self.doc)
    
    async def sync_with_peers(
        self, 
        peer_changes: bytes
    ) -> CanvasData:
        """ä¸å…¶ä»–ç”¨æˆ·åŒæ­¥"""
        # Automerge è‡ªåŠ¨ä¸‰å‘åˆå¹¶
        self.doc = Automerge.merge(self.doc, peer_changes)
        return self._to_canvas_data(self.doc)

# åŸºäº OT (Operational Transformation) çš„å¤‡é€‰æ–¹æ¡ˆ
class OTCanvas:
    """åŸºäº OT çš„ Canvas åä½œå¼•æ“"""
    
    def __init__(self):
        self.version = 0
        self.canvas_data: CanvasData = None
        self.pending_operations: List[Operation] = []
    
    async def apply_operation(
        self, 
        operation: Operation,
        base_version: int
    ) -> CanvasData:
        """åº”ç”¨æ“ä½œï¼ˆéœ€è¦è½¬æ¢å†²çªæ“ä½œï¼‰"""
        
        if base_version < self.version:
            # æœ‰å…¶ä»–æ“ä½œå·²ç»åº”ç”¨ï¼Œéœ€è¦è½¬æ¢å½“å‰æ“ä½œ
            operations_to_transform = [
                op for op in self.operations_log 
                if op.version > base_version
            ]
            
            transformed_op = self.transform_operation(
                operation,
                operations_to_transform
            )
        else:
            transformed_op = operation
        
        # åº”ç”¨è½¬æ¢åçš„æ“ä½œ
        self.canvas_data = self.apply_to_canvas(
            self.canvas_data, 
            transformed_op
        )
        
        self.version += 1
        self.operations_log.append(transformed_op)
        
        return self.canvas_data
    
    def transform_operation(
        self, 
        op: Operation,
        against_ops: List[Operation]
    ) -> Operation:
        """æ“ä½œè½¬æ¢ï¼ˆOT æ ¸å¿ƒç®—æ³•ï¼‰"""
        transformed = op
        
        for other_op in against_ops:
            transformed = self._transform_pair(transformed, other_op)
        
        return transformed
    
    def _transform_pair(self, op1: Operation, op2: Operation) -> Operation:
        """è½¬æ¢ä¸¤ä¸ªæ“ä½œï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        if op1.type == OperationType.INSERT and op2.type == OperationType.INSERT:
            # ä¸¤ä¸ªæ’å…¥æ“ä½œ
            if op1.position <= op2.position:
                # op1 åœ¨å‰ï¼Œop2 ä½ç½®éœ€è¦åç§»
                return Operation(
                    **op1.__dict__,
                    position=op1.position
                )
            else:
                # op2 åœ¨å‰ï¼Œop1 ä½ç½®éœ€è¦åç§»
                return Operation(
                    **op1.__dict__,
                    position=op1.position + 1
                )
        
        # ... æ›´å¤šè½¬æ¢è§„åˆ™
        return op1

# æ™ºèƒ½å†²çªè§£å†³å™¨
class ConflictResolver:
    """æ™ºèƒ½å†²çªè§£å†³"""
    
    async def resolve_conflict(
        self,
        local_change: NodeDiff,
        remote_change: NodeDiff,
        strategy: ConflictResolutionStrategy
    ) -> NodeDiff:
        """è§£å†³å†²çª"""
        
        if strategy == ConflictResolutionStrategy.LAST_WRITE_WINS:
            # æ¯”è¾ƒæ—¶é—´æˆ³
            return (
                remote_change 
                if remote_change.timestamp > local_change.timestamp 
                else local_change
            )
        
        elif strategy == ConflictResolutionStrategy.MERGE:
            # æ™ºèƒ½åˆå¹¶
            return await self.intelligent_merge(local_change, remote_change)
        
        elif strategy == ConflictResolutionStrategy.MANUAL:
            # æäº¤åˆ°å†²çªé˜Ÿåˆ—ï¼Œç­‰å¾…äººå·¥è§£å†³
            await self.conflict_queue.add({
                'local': local_change,
                'remote': remote_change,
                'canvas_id': local_change.canvas_id
            })
            # è¿”å›ä¸´æ—¶å†²çªæ ‡è®°
            return self.create_conflict_marker(local_change, remote_change)
    
    async def intelligent_merge(
        self,
        local: NodeDiff,
        remote: NodeDiff
    ) -> NodeDiff:
        """æ™ºèƒ½åˆå¹¶ï¼ˆä½¿ç”¨ LLMï¼‰"""
        # ä½¿ç”¨å°æ¨¡å‹åˆ¤æ–­å†²çªæ€§è´¨
        prompt = f"""
        Two users edited the same node simultaneously:
        
        User A's change: {local.to_dict()}
        User B's change: {remote.to_dict()}
        
        Suggest a merged version that preserves both users' intentions.
        """
        
        llm_suggestion = await self.llm.invoke(prompt)
        
        # è§£æ LLM å»ºè®®å¹¶åº”ç”¨
        merged = self.parse_merge_suggestion(llm_suggestion)
        
        return merged
```

**åä½œèƒ½åŠ›å¯¹æ¯”ï¼š**

| ç‰¹æ€§ | Refly | AgenticX (CRDT) | AgenticX (OT) |
|------|-------|----------------|---------------|
| å®æ—¶åä½œ | âŒ | âœ… | âœ… |
| ç¦»çº¿ç¼–è¾‘ | âš ï¸ æœ‰é™ | âœ… å®Œå…¨æ”¯æŒ | âš ï¸ éœ€è¦åœ¨çº¿è½¬æ¢ |
| å†²çªè‡ªåŠ¨è§£å†³ | âŒ | âœ… | âœ… |
| æ€§èƒ½å¼€é”€ | ä½ | ä¸­ç­‰ | é«˜ |
| å®ç°å¤æ‚åº¦ | ä½ | é«˜ | å¾ˆé«˜ |

**AgenticX å®æ–½å»ºè®®ï¼š**
1. **MVPé˜¶æ®µ**ï¼šä½¿ç”¨ Refly çš„äº‹åŠ¡å¼åŒæ­¥ + Last-Write-Wins
2. **å¤šç”¨æˆ·é˜¶æ®µ**ï¼šå¼•å…¥ CRDT (Automerge/Yjs) æ”¯æŒå®æ—¶åä½œ
3. **ä¼ä¸šçº§**ï¼šå®ç°å®Œæ•´çš„ OT + äººå·¥å†²çªè§£å†³æµç¨‹

---

## å·¥ç¨‹åŒ–è½åœ°è·¯çº¿å›¾

åŸºäºä»¥ä¸Š5ä¸ªæ ¸å¿ƒè¿½é—®ï¼ŒAgenticX çš„åˆ†é˜¶æ®µå®æ–½å»ºè®®ï¼š

### Phase 1: åŸºç¡€èƒ½åŠ›æ„å»ºï¼ˆ0-3ä¸ªæœˆï¼‰
- âœ… å®ç° Refly é£æ ¼çš„è½®è¯¢è°ƒåº¦å™¨
- âœ… åŸºç¡€ä¸Šä¸‹æ–‡ç®¡ç†ï¼ˆå…ƒæ•°æ®ä¿ç•™ + æ‡’åŠ è½½ï¼‰
- âœ… å·¥å…·ç³»ç»ŸåŸºç¡€æŠ½è±¡å±‚
- âœ… ç®€å•çš„è¶…æ—¶æ£€æµ‹

### Phase 2: æ€§èƒ½ä¼˜åŒ–ï¼ˆ3-6ä¸ªæœˆï¼‰
- ğŸ”„ å¼•å…¥äº‹ä»¶é©±åŠ¨è°ƒåº¦ï¼ˆä¿ç•™è½®è¯¢å…œåº•ï¼‰
- ğŸ”„ ä¸Šä¸‹æ–‡å‹ç¼©ä¸æ‘˜è¦
- ğŸ”„ å·¥å…·åè®®é€‚é…å™¨ï¼ˆMCP + LangChainï¼‰
- ğŸ”„ èŠ‚ç‚¹é‡è¯•æœºåˆ¶

### Phase 3: å¯é æ€§å¢å¼ºï¼ˆ6-12ä¸ªæœˆï¼‰
- ğŸ”„ æ£€æŸ¥ç‚¹ç³»ç»Ÿ + æ•…éšœæ¢å¤
- ğŸ”„ RAG-based ä¸Šä¸‹æ–‡æ£€ç´¢
- ğŸ”„ æ™ºèƒ½å·¥å…·æ¨è
- ğŸ”„ æ­»ä¿¡é˜Ÿåˆ— + äººå·¥ä»‹å…¥

### Phase 4: åä½œä¸æ‰©å±•ï¼ˆ12-18ä¸ªæœˆï¼‰
- ğŸ”„ CRDT-based å®æ—¶åä½œ
- ğŸ”„ è¶…å¤§è§„æ¨¡ä¸Šä¸‹æ–‡æ”¯æŒï¼ˆç™¾ä¸‡Tokenï¼‰
- ğŸ”„ å·¥å…·ç”Ÿæ€å¸‚åœº
- ğŸ”„ å®Œæ•´çš„å¯è§‚æµ‹æ€§å¹³å°

---

**ä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼š**
1. é€‰æ‹©1-2ä¸ªè¿½é—®è¿›è¡Œ **åŸå‹éªŒè¯**ï¼ˆå»ºè®®ä»è¿½é—®1å’Œè¿½é—®3å¼€å§‹ï¼‰
2. åœ¨ AgenticX ä¸­å®ç° **æœ€å°å¯è¡Œæ–¹æ¡ˆ**ï¼ˆMVPï¼‰
3. æ”¶é›†çœŸå®åœºæ™¯æ•°æ®ï¼Œè¿­ä»£ä¼˜åŒ–

